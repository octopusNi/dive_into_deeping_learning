{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2ef73a8",
      "metadata": {
        "id": "c2ef73a8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a66c1f7",
      "metadata": {
        "id": "8a66c1f7",
        "outputId": "39dc52b4-300c-4b35-e0b7-59ee67f728f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
            "Collecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.23.5 (from d2l==1.0.3)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib-inline==0.1.6 (from d2l==1.0.3)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting requests==2.31.0 (from d2l==1.0.3)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (11.1.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->d2l==1.0.3) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.17.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.4.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.18.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.2.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n",
            "Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, qtpy, pyparsing, numpy, matplotlib-inline, jedi, scipy, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "treescope 0.1.8 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.4 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.36.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.1 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.20.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.1.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.2 jupyter-1.0.0 matplotlib-3.7.2 matplotlib-inline-0.1.6 numpy-1.23.5 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.6.1 qtpy-2.4.3 requests-2.31.0 scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "b2a05d1cc903417789a82072de4f9ad4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad19fa4",
      "metadata": {
        "origin_pos": 1,
        "id": "0ad19fa4"
      },
      "source": [
        "# Probability and Statistics\n",
        ":label:`sec_prob`\n",
        "\n",
        "One way or another,\n",
        "machine learning is all about uncertainty.\n",
        "In supervised learning, we want to predict\n",
        "something unknown (the *target*)\n",
        "given something known (the *features*).\n",
        "Depending on our objective,\n",
        "we might attempt to predict\n",
        "the most likely value of the target.\n",
        "Or we might predict the value with the smallest\n",
        "expected distance from the target.\n",
        "And sometimes we wish not only\n",
        "to predict a specific value\n",
        "but to *quantify our uncertainty*.\n",
        "For example, given some features\n",
        "describing a patient,\n",
        "we might want to know *how likely* they are\n",
        "to suffer a heart attack in the next year.\n",
        "In unsupervised learning,\n",
        "we often care about uncertainty.\n",
        "To determine whether a set of measurements are anomalous,\n",
        "it helps to know how likely one is\n",
        "to observe values in a population of interest.\n",
        "Furthermore, in reinforcement learning,\n",
        "we wish to develop agents\n",
        "that act intelligently in various environments.\n",
        "This requires reasoning about\n",
        "how an environment might be expected to change\n",
        "and what rewards one might expect to encounter\n",
        "in response to each of the available actions.\n",
        "\n",
        "*Probability* is the mathematical field\n",
        "concerned with reasoning under uncertainty.\n",
        "Given a probabilistic model of some process,\n",
        "we can reason about the likelihood of various events.\n",
        "The use of probabilities to describe\n",
        "the frequencies of repeatable events\n",
        "(like coin tosses)\n",
        "is fairly uncontroversial.\n",
        "In fact, *frequentist* scholars adhere\n",
        "to an interpretation of probability\n",
        "that applies *only* to such repeatable events.\n",
        "By contrast *Bayesian* scholars\n",
        "use the language of probability more broadly\n",
        "to formalize reasoning under uncertainty.\n",
        "Bayesian probability is characterized\n",
        "by two unique features:\n",
        "(i) assigning degrees of belief\n",
        "to non-repeatable events,\n",
        "e.g., what is the *probability*\n",
        "that a dam will collapse?;\n",
        "and (ii) subjectivity. While Bayesian\n",
        "probability provides unambiguous rules\n",
        "for how one should update their beliefs\n",
        "in light of new evidence,\n",
        "it allows for different individuals\n",
        "to start off with different *prior* beliefs.\n",
        "*Statistics* helps us to reason backwards,\n",
        "starting off with collection and organization of data\n",
        "and backing out to what inferences\n",
        "we might draw about the process\n",
        "that generated the data.\n",
        "Whenever we analyze a dataset, hunting for patterns\n",
        "that we hope might characterize a broader population,\n",
        "we are employing statistical thinking.\n",
        "Many courses, majors, theses, careers, departments,\n",
        "companies, and institutions have been devoted\n",
        "to the study of probability and statistics.\n",
        "While this section only scratches the surface,\n",
        "we will provide the foundation\n",
        "that you need to begin building models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "15d26295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:41.010215Z",
          "iopub.status.busy": "2023-08-18T19:35:41.009884Z",
          "iopub.status.idle": "2023-08-18T19:35:44.240517Z",
          "shell.execute_reply": "2023-08-18T19:35:44.239244Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "15d26295"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fa88a",
      "metadata": {
        "origin_pos": 6,
        "id": "390fa88a"
      },
      "source": [
        "## A Simple Example: Tossing Coins\n",
        "\n",
        "Imagine that we plan to toss a coin\n",
        "and want to quantify how likely\n",
        "we are to see heads (vs. tails).\n",
        "If the coin is *fair*,\n",
        "then both outcomes\n",
        "(heads and tails),\n",
        "are equally likely.\n",
        "Moreover if we plan to toss the coin $n$ times\n",
        "then the fraction of heads\n",
        "that we *expect* to see\n",
        "should exactly match\n",
        "the *expected* fraction of tails.\n",
        "One intuitive way to see this\n",
        "is by symmetry:\n",
        "for every possible outcome\n",
        "with $n_\\textrm{h}$ heads and $n_\\textrm{t} = (n - n_\\textrm{h})$ tails,\n",
        "there is an equally likely outcome\n",
        "with $n_\\textrm{t}$ heads and $n_\\textrm{h}$ tails.\n",
        "Note that this is only possible\n",
        "if on average we expect to see\n",
        "$1/2$ of tosses come up heads\n",
        "and $1/2$ come up tails.\n",
        "Of course, if you conduct this experiment\n",
        "many times with $n=1000000$ tosses each,\n",
        "you might never see a trial\n",
        "where $n_\\textrm{h} = n_\\textrm{t}$ exactly.\n",
        "\n",
        "\n",
        "Formally, the quantity $1/2$ is called a *probability*\n",
        "and here it captures the certainty with which\n",
        "any given toss will come up heads.\n",
        "Probabilities assign scores between $0$ and $1$\n",
        "to outcomes of interest, called *events*.\n",
        "Here the event of interest is $\\textrm{heads}$\n",
        "and we denote the corresponding probability $P(\\textrm{heads})$.\n",
        "A probability of $1$ indicates absolute certainty\n",
        "(imagine a trick coin where both sides were heads)\n",
        "and a probability of $0$ indicates impossibility\n",
        "(e.g., if both sides were tails).\n",
        "The frequencies $n_\\textrm{h}/n$ and $n_\\textrm{t}/n$ are not probabilities\n",
        "but rather *statistics*.\n",
        "Probabilities are *theoretical* quantities\n",
        "that underly the data generating process.\n",
        "Here, the probability $1/2$\n",
        "is a property of the coin itself.\n",
        "By contrast, statistics are *empirical* quantities\n",
        "that are computed as functions of the observed data.\n",
        "Our interests in probabilistic and statistical quantities\n",
        "are inextricably intertwined.\n",
        "We often design special statistics called *estimators*\n",
        "that, given a dataset, produce *estimates*\n",
        "of model parameters such as probabilities.\n",
        "Moreover, when those estimators satisfy\n",
        "a nice property called *consistency*,\n",
        "our estimates will converge\n",
        "to the corresponding probability.\n",
        "In turn, these inferred probabilities\n",
        "tell about the likely statistical properties\n",
        "of data from the same population\n",
        "that we might encounter in the future.\n",
        "\n",
        "Suppose that we stumbled upon a real coin\n",
        "for which we did not know\n",
        "the true $P(\\textrm{heads})$.\n",
        "To investigate this quantity\n",
        "with statistical methods,\n",
        "we need to (i) collect some data;\n",
        "and (ii) design an estimator.\n",
        "Data acquisition here is easy;\n",
        "we can toss the coin many times\n",
        "and record all the outcomes.\n",
        "Formally, drawing realizations\n",
        "from some underlying random process\n",
        "is called *sampling*.\n",
        "As you might have guessed,\n",
        "one natural estimator\n",
        "is the ratio of\n",
        "the number of observed *heads*\n",
        "to the total number of tosses.\n",
        "\n",
        "Now, suppose that the coin was in fact fair,\n",
        "i.e., $P(\\textrm{heads}) = 0.5$.\n",
        "To simulate tosses of a fair coin,\n",
        "we can invoke any random number generator.\n",
        "There are some easy ways to draw samples\n",
        "of an event with probability $0.5$.\n",
        "For example Python's `random.random`\n",
        "yields numbers in the interval $[0,1]$\n",
        "where the probability of lying\n",
        "in any sub-interval $[a, b] \\subset [0,1]$\n",
        "is equal to $b-a$.\n",
        "Thus we can get out `0` and `1` with probability `0.5` each\n",
        "by testing whether the returned float number is greater than `0.5`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3a500e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.245216Z",
          "iopub.status.busy": "2023-08-18T19:35:44.244448Z",
          "iopub.status.idle": "2023-08-18T19:35:44.250559Z",
          "shell.execute_reply": "2023-08-18T19:35:44.249469Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "3a500e66",
        "outputId": "e3cb7d4a-c1aa-4f04-c4b4-9eca5a336801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [54, 46]\n"
          ]
        }
      ],
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096c1837",
      "metadata": {
        "origin_pos": 8,
        "id": "096c1837"
      },
      "source": [
        "More generally, we can simulate multiple draws\n",
        "from any variable with a finite number\n",
        "of possible outcomes\n",
        "(like the toss of a coin or roll of a die)\n",
        "by calling the multinomial function,\n",
        "setting the first argument\n",
        "to the number of draws\n",
        "and the second as a list of probabilities\n",
        "associated with each of the possible outcomes.\n",
        "To simulate ten tosses of a fair coin,\n",
        "we assign probability vector `[0.5, 0.5]`,\n",
        "interpreting index 0 as heads\n",
        "and index 1 as tails.\n",
        "The function returns a vector\n",
        "with length equal to the number\n",
        "of possible outcomes (here, 2),\n",
        "where the first component tells us\n",
        "the number of occurrences of heads\n",
        "and the second component tells us\n",
        "the number of occurrences of tails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b70ba754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.256289Z",
          "iopub.status.busy": "2023-08-18T19:35:44.255841Z",
          "iopub.status.idle": "2023-08-18T19:35:44.292323Z",
          "shell.execute_reply": "2023-08-18T19:35:44.291255Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "b70ba754",
        "outputId": "cab62361-18eb-495b-ff81-645bd71a0e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([53., 47.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca81b0bc",
      "metadata": {
        "origin_pos": 13,
        "id": "ca81b0bc"
      },
      "source": [
        "Each time you run this sampling process,\n",
        "you will receive a new random value\n",
        "that may differ from the previous outcome.\n",
        "Dividing by the number of tosses\n",
        "gives us the *frequency*\n",
        "of each outcome in our data.\n",
        "Note that these frequencies,\n",
        "just like the probabilities\n",
        "that they are intended\n",
        "to estimate, sum to $1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d4157453",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.297194Z",
          "iopub.status.busy": "2023-08-18T19:35:44.296806Z",
          "iopub.status.idle": "2023-08-18T19:35:44.309679Z",
          "shell.execute_reply": "2023-08-18T19:35:44.308709Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "d4157453",
        "outputId": "c83e8001-6dd8-4913-ca8c-533344898323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5100, 0.4900])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5135ef92",
      "metadata": {
        "origin_pos": 18,
        "id": "5135ef92"
      },
      "source": [
        "Here, even though our simulated coin is fair\n",
        "(we ourselves set the probabilities `[0.5, 0.5]`),\n",
        "the counts of heads and tails may not be identical.\n",
        "That is because we only drew a relatively small number of samples.\n",
        "If we did not implement the simulation ourselves,\n",
        "and only saw the outcome,\n",
        "how would we know if the coin were slightly unfair\n",
        "or if the possible deviation from $1/2$ was\n",
        "just an artifact of the small sample size?\n",
        "Let's see what happens when we simulate 10,000 tosses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3b639145",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.313908Z",
          "iopub.status.busy": "2023-08-18T19:35:44.313549Z",
          "iopub.status.idle": "2023-08-18T19:35:44.325094Z",
          "shell.execute_reply": "2023-08-18T19:35:44.324133Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "3b639145",
        "outputId": "f1051838-4518-46ab-911b-246358a7bedd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4999, 0.5001])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8725b688",
      "metadata": {
        "origin_pos": 23,
        "id": "8725b688"
      },
      "source": [
        "In general, for averages of repeated events (like coin tosses),\n",
        "as the number of repetitions grows,\n",
        "our estimates are guaranteed to converge\n",
        "to the true underlying probabilities.\n",
        "The mathematical formulation of this phenomenon\n",
        "is called the *law of large numbers*\n",
        "and the *central limit theorem*\n",
        "tells us that in many situations,\n",
        "as the sample size $n$ grows,\n",
        "these errors should go down\n",
        "at a rate of $(1/\\sqrt{n})$.\n",
        "Let's get some more intuition by studying\n",
        "how our estimate evolves as we grow\n",
        "the number of tosses from 1 to 10,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fda7f94d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.329246Z",
          "iopub.status.busy": "2023-08-18T19:35:44.328647Z",
          "iopub.status.idle": "2023-08-18T19:35:44.675913Z",
          "shell.execute_reply": "2023-08-18T19:35:44.674711Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "id": "fda7f94d",
        "outputId": "a556611e-1ce5-40fe-8097-865ef6956df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2025-02-20T14:11:05.246242</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m78f67a305e\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m78f67a305e\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"me9ae4ce91c\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#me9ae4ce91c\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 16.02 \nL 55.217716 16.02 \nL 55.309034 133.619998 \nL 55.354693 126.27 \nL 55.446011 89.520004 \nL 55.5145 98.339995 \nL 55.651477 116.819999 \nL 55.674307 112.238179 \nL 55.765625 97.43538 \nL 55.834114 101.178624 \nL 56.01675 111.371352 \nL 56.085239 117.449998 \nL 56.130898 112.619999 \nL 56.199387 106.18 \nL 56.245046 109.849787 \nL 56.336364 109.408235 \nL 56.404853 114.019999 \nL 56.54183 110.1 \nL 56.587489 112.755486 \nL 56.655978 111.004615 \nL 56.815785 106.670001 \nL 56.884273 110.1 \nL 56.952762 108.743077 \nL 56.998421 106.424998 \nL 57.04408 108.52244 \nL 57.181058 114.242728 \nL 57.249546 112.943076 \nL 57.409353 109.619997 \nL 57.432183 110.456365 \nL 57.477842 108.586335 \nL 57.728967 102.644995 \nL 57.774626 104.22 \nL 57.820285 102.699312 \nL 57.843115 101.958456 \nL 57.888774 103.478818 \nL 58.09424 106.97625 \nL 58.299706 102.288615 \nL 58.322535 102.941739 \nL 58.391024 104.84553 \nL 58.436683 103.603213 \nL 58.573661 101.260268 \nL 58.59649 101.868002 \nL 58.61932 102.467683 \nL 58.664979 101.337642 \nL 58.687808 101.92909 \nL 58.710638 101.374841 \nL 58.779127 101.987087 \nL 58.961763 106.3453 \nL 59.007422 105.270001 \nL 59.12157 102.690522 \nL 59.167229 103.715999 \nL 59.304206 104.707294 \nL 59.327036 104.22 \nL 59.372695 105.178695 \nL 59.418354 106.116772 \nL 59.464013 105.158298 \nL 59.509672 104.22 \nL 59.555331 105.138752 \nL 59.62382 106.481538 \nL 59.715138 106.43608 \nL 59.943434 103.797989 \nL 60.103241 105.036669 \nL 60.217389 104.619095 \nL 60.263048 105.406545 \nL 60.354366 105.385637 \nL 60.377196 104.993687 \nL 60.422855 105.753915 \nL 60.765298 111.059999 \nL 60.810957 111.004615 \nL 60.970764 109.775908 \nL 61.336037 114.673334 \nL 61.358866 114.309299 \nL 61.427355 114.520731 \nL 61.473014 113.806954 \nL 61.518673 114.372516 \nL 61.587162 113.950248 \nL 61.655651 113.536901 \nL 61.67848 113.813683 \nL 61.70131 114.088531 \nL 61.746969 113.407502 \nL 61.861117 112.347643 \nL 61.883946 112.619999 \nL 62.089412 113.825943 \nL 62.157901 113.443529 \nL 62.18073 113.700781 \nL 62.272049 114.146044 \nL 62.22639 113.63942 \nL 62.317708 114.082622 \nL 62.454685 112.791161 \nL 62.477515 113.040002 \nL 62.500344 113.287292 \nL 62.546003 112.685014 \nL 62.591662 113.175694 \nL 62.72864 112.480423 \nL 62.751469 112.721205 \nL 62.819958 112.381788 \nL 63.002594 110.648571 \nL 63.025424 110.886277 \nL 63.048254 111.122611 \nL 63.116742 110.809654 \nL 63.139572 110.53805 \nL 63.185231 111.004615 \nL 63.20806 110.734772 \nL 63.299379 110.661571 \nL 63.367867 111.344793 \nL 63.390697 111.080002 \nL 63.436356 111.529392 \nL 63.459186 111.752231 \nL 63.527674 111.44951 \nL 63.710311 110.351553 \nL 63.847288 111.183158 \nL 63.870118 110.933386 \nL 64.098413 108.957084 \nL 64.121243 109.169998 \nL 64.212561 109.120002 \nL 64.28105 109.746316 \nL 64.395197 109.022971 \nL 64.418027 109.228888 \nL 64.440856 109.433795 \nL 64.509345 109.179902 \nL 64.532175 108.952684 \nL 64.577834 109.357866 \nL 64.600663 109.558983 \nL 64.646322 109.108195 \nL 64.714811 108.862103 \nL 64.737641 109.061527 \nL 64.806129 109.654121 \nL 64.851788 109.212454 \nL 64.874618 108.993174 \nL 64.920277 109.383937 \nL 64.943107 109.577946 \nL 64.988766 109.142792 \nL 65.011595 108.926729 \nL 65.057254 109.312376 \nL 65.080084 109.097418 \nL 65.125743 109.479632 \nL 65.171402 109.052879 \nL 65.194232 109.242777 \nL 65.217061 109.03091 \nL 65.26272 109.408235 \nL 65.28555 109.197424 \nL 65.331209 109.571458 \nL 65.376868 109.152886 \nL 65.422527 108.73804 \nL 65.468186 109.109136 \nL 65.536675 108.882554 \nL 65.605164 109.430941 \nL 65.627993 109.226985 \nL 65.673652 109.588696 \nL 65.901948 110.600426 \nL 66.198732 108.785218 \nL 66.29005 109.472156 \nL 66.358539 109.26 \nL 66.381369 109.070102 \nL 66.427028 109.408235 \nL 66.472687 109.387275 \nL 66.609664 110.02958 \nL 66.792301 108.898588 \nL 66.81513 109.062353 \nL 66.883619 109.549825 \nL 66.929278 109.1866 \nL 67.043426 108.969233 \nL 67.111914 108.773347 \nL 67.180403 109.250416 \nL 67.203233 109.073508 \nL 67.248892 109.388621 \nL 67.271721 109.212454 \nL 67.36304 109.505392 \nL 67.31738 109.193686 \nL 67.408699 109.485673 \nL 67.477187 109.619997 \nL 67.545676 109.101918 \nL 67.636994 109.066154 \nL 67.682653 109.370363 \nL 67.728312 109.03091 \nL 67.773972 109.333042 \nL 67.956608 109.889998 \nL 68.047926 109.537019 \nL 68.070756 109.683719 \nL 68.093585 109.829894 \nL 68.139244 109.499578 \nL 68.321881 108.507499 \nL 68.34471 108.652927 \nL 68.413199 109.08621 \nL 68.458858 108.766392 \nL 68.550176 108.133313 \nL 68.618665 108.263122 \nL 68.824131 108.93973 \nL 68.89262 108.76942 \nL 68.915449 108.908371 \nL 68.961108 109.184902 \nL 69.006768 108.877428 \nL 69.029597 108.724451 \nL 69.075256 108.999309 \nL 69.120915 109.272375 \nL 69.166574 108.968124 \nL 69.189404 109.104042 \nL 69.303552 108.922098 \nL 69.349211 109.191016 \nL 69.4177 109.025768 \nL 69.623166 108.260756 \nL 69.645995 108.393504 \nL 69.691654 108.103021 \nL 69.874291 107.233045 \nL 69.89712 107.365115 \nL 69.91995 107.496779 \nL 69.965609 107.214445 \nL 70.125416 106.239847 \nL 70.193904 106.364683 \nL 70.285223 106.618187 \nL 70.308052 106.481538 \nL 70.4222 106.068501 \nL 70.44503 106.19758 \nL 70.513518 106.320003 \nL 70.536348 106.185825 \nL 70.604836 105.785678 \nL 70.650496 106.041238 \nL 70.833132 106.534283 \nL 70.855962 106.402534 \nL 70.901621 106.652222 \nL 71.015768 107.015968 \nL 71.038598 106.885034 \nL 71.152746 106.74 \nL 71.358212 107.578817 \nL 71.381041 107.44986 \nL 71.518019 106.930056 \nL 71.540848 107.049287 \nL 71.609337 107.405 \nL 71.654996 107.151854 \nL 71.860462 106.512477 \nL 71.997439 106.972512 \nL 72.020269 106.849269 \nL 72.043098 106.726358 \nL 72.088758 106.95765 \nL 72.111587 106.835096 \nL 72.225735 106.935665 \nL 72.271394 106.692896 \nL 72.339883 106.80032 \nL 72.362712 106.914021 \nL 72.408371 106.673245 \nL 72.591008 106.185136 \nL 72.659496 106.52287 \nL 72.705156 106.287188 \nL 72.864962 105.927095 \nL 73.047599 106.36023 \nL 73.161747 106.010862 \nL 73.184576 106.120379 \nL 73.253065 106.00182 \nL 73.344383 106.43608 \nL 73.50419 106.087248 \nL 73.52702 106.194625 \nL 73.572679 105.970866 \nL 73.595508 106.077991 \nL 73.732486 105.847308 \nL 73.800974 105.733233 \nL 73.869463 106.050769 \nL 73.937952 105.722188 \nL 74.00644 105.823635 \nL 74.052099 106.033058 \nL 74.097758 105.815896 \nL 74.303224 105.272504 \nL 74.371713 105.583379 \nL 74.417372 105.370891 \nL 74.463031 105.159407 \nL 74.50869 105.365455 \nL 74.55435 105.57053 \nL 74.622838 105.462254 \nL 74.736986 105.146254 \nL 74.759816 105.247974 \nL 74.919622 105.545548 \nL 75.079429 105.029172 \nL 75.102259 105.129278 \nL 75.170748 105.025482 \nL 75.239236 105.323755 \nL 75.376214 105.11695 \nL 75.444702 105.213245 \nL 75.467532 105.112913 \nL 75.650168 104.711636 \nL 75.695827 104.906765 \nL 75.741486 104.709455 \nL 75.924123 104.317031 \nL 76.152418 104.891819 \nL 76.220907 104.602645 \nL 76.289396 104.696759 \nL 76.517691 105.257647 \nL 76.631839 104.782981 \nL 76.677498 104.969046 \nL 76.882964 105.611168 \nL 76.905794 105.51706 \nL 77.042771 105.140671 \nL 77.065601 105.231677 \nL 77.11126 105.413132 \nL 77.156919 105.227476 \nL 77.339555 104.855839 \nL 77.499362 105.12184 \nL 77.545021 104.940001 \nL 77.59068 105.118165 \nL 77.61351 105.206979 \nL 77.659169 105.025886 \nL 77.796146 104.843007 \nL 77.978783 105.191171 \nL 78.13859 104.92139 \nL 78.298397 105.177749 \nL 78.344056 105.002066 \nL 78.389715 105.17398 \nL 78.503863 105.42822 \nL 78.526692 105.34082 \nL 78.572351 105.166536 \nL 78.61801 105.336457 \nL 78.800647 105.668697 \nL 78.914795 105.407307 \nL 78.937624 105.490895 \nL 79.006113 105.571724 \nL 79.028942 105.486027 \nL 79.14309 105.395999 \nL 79.211579 105.64393 \nL 79.280068 105.556362 \nL 79.302897 105.471654 \nL 79.348556 105.635866 \nL 79.508363 106.04026 \nL 79.531193 105.955894 \nL 79.599681 105.868599 \nL 79.622511 105.949412 \nL 79.64534 106.030077 \nL 79.691 105.862459 \nL 79.713829 105.778886 \nL 79.759488 105.939775 \nL 79.782318 105.856366 \nL 79.827977 106.016666 \nL 79.873636 105.850315 \nL 79.964954 105.681876 \nL 79.987784 105.761674 \nL 80.147591 105.993677 \nL 80.261739 105.744841 \nL 80.284568 105.823635 \nL 80.375886 105.977611 \nL 80.398716 105.896199 \nL 80.512864 105.65027 \nL 80.535693 105.72837 \nL 80.604182 105.803484 \nL 80.627011 105.722961 \nL 80.741159 105.637501 \nL 80.763989 105.714917 \nL 80.809648 105.555174 \nL 80.832477 105.475518 \nL 80.878137 105.629946 \nL 81.083603 106.007314 \nL 81.311898 105.529519 \nL 81.540194 105.976365 \nL 81.563023 105.898549 \nL 81.608682 106.047978 \nL 81.631512 105.970303 \nL 81.72283 106.267636 \nL 81.791319 106.186724 \nL 82.019614 105.720001 \nL 82.042444 105.793664 \nL 82.088103 105.641375 \nL 82.133762 105.489602 \nL 82.202251 105.560878 \nL 82.339228 105.850588 \nL 82.362058 105.775164 \nL 82.476205 105.547425 \nL 82.499035 105.62 \nL 82.613183 105.687554 \nL 82.636012 105.613018 \nL 82.681671 105.757095 \nL 82.704501 105.682686 \nL 82.727331 105.754551 \nL 82.77299 105.606105 \nL 82.841478 105.529903 \nL 82.864308 105.601532 \nL 83.092603 106.167178 \nL 83.115433 106.093531 \nL 83.206751 105.943776 \nL 83.229581 106.014143 \nL 83.298069 106.081366 \nL 83.320899 106.008323 \nL 83.457876 105.857286 \nL 83.480706 105.927095 \nL 83.526365 105.782319 \nL 83.549195 105.852018 \nL 83.594854 105.70771 \nL 83.640513 105.846782 \nL 83.686172 105.985412 \nL 83.731831 105.841583 \nL 84.028615 105.196901 \nL 84.051445 105.265848 \nL 84.097104 105.124973 \nL 84.119933 105.054701 \nL 84.165593 105.192285 \nL 84.348229 105.462254 \nL 84.530865 105.180188 \nL 84.667843 105.312258 \nL 84.80482 105.171309 \nL 84.82765 105.238474 \nL 84.873309 105.101321 \nL 85.124434 104.623353 \nL 85.192923 104.689504 \nL 85.215752 104.622128 \nL 85.284241 104.554343 \nL 85.30707 104.620909 \nL 85.375559 104.820001 \nL 85.444048 104.752127 \nL 85.489707 104.618496 \nL 85.535366 104.750528 \nL 85.558195 104.816395 \nL 85.603855 104.683164 \nL 85.740832 104.549349 \nL 85.809321 104.745781 \nL 85.85498 104.613748 \nL 86.060446 104.285188 \nL 86.151764 104.414987 \nL 86.174593 104.349898 \nL 86.265912 104.22 \nL 86.288741 104.28471 \nL 86.3344 104.413846 \nL 86.402889 104.348947 \nL 86.494207 104.091432 \nL 86.539866 104.22 \nL 86.562696 104.284147 \nL 86.608355 104.155947 \nL 86.631185 104.22 \nL 86.699673 104.156136 \nL 86.722503 104.22 \nL 86.836651 104.410771 \nL 86.85948 104.347091 \nL 86.88231 104.283501 \nL 86.927969 104.410224 \nL 86.950798 104.346723 \nL 86.973628 104.409951 \nL 87.019287 104.283227 \nL 87.247583 103.906118 \nL 87.270412 103.969077 \nL 87.316071 103.844147 \nL 87.567196 103.411969 \nL 87.612855 103.537246 \nL 87.658515 103.41424 \nL 87.978128 102.808313 \nL 88.183594 103.244066 \nL 88.206424 103.183788 \nL 88.38906 102.704538 \nL 88.434719 102.827691 \nL 88.640185 103.137052 \nL 88.708674 103.079224 \nL 88.731504 103.139996 \nL 88.822822 103.262603 \nL 88.845651 103.20346 \nL 89.005458 103.029712 \nL 89.233754 103.510613 \nL 89.256583 103.452017 \nL 89.370731 103.395703 \nL 89.599027 103.752094 \nL 89.850152 103.2329 \nL 89.872981 103.29158 \nL 90.009959 103.410823 \nL 90.124107 103.240639 \nL 90.146936 103.298856 \nL 90.306743 103.589586 \nL 90.329573 103.532725 \nL 90.420891 103.420254 \nL 90.44372 103.477862 \nL 90.580698 103.594465 \nL 90.603527 103.538045 \nL 90.649186 103.65243 \nL 90.808993 103.824485 \nL 90.877482 103.656057 \nL 90.923141 103.769422 \nL 91.014459 103.882934 \nL 91.037289 103.826998 \nL 91.219925 103.605557 \nL 91.288414 103.773985 \nL 91.334073 103.663186 \nL 91.425391 103.553501 \nL 91.448221 103.609426 \nL 91.47105 103.665278 \nL 91.516709 103.555173 \nL 91.630857 103.502034 \nL 91.653687 103.557675 \nL 91.699346 103.448253 \nL 91.745005 103.339105 \nL 91.813494 103.395703 \nL 91.950471 103.508269 \nL 92.155937 103.239997 \nL 92.247255 103.351039 \nL 92.270085 103.29729 \nL 92.49838 102.979265 \nL 92.566869 103.143077 \nL 92.612528 103.03683 \nL 92.635358 102.983807 \nL 92.681017 103.092672 \nL 92.703846 103.039711 \nL 92.817994 103.096772 \nL 93.000631 102.889284 \nL 93.04629 102.997213 \nL 93.091949 102.892491 \nL 93.206097 102.737647 \nL 93.228926 102.791449 \nL 93.297415 102.741201 \nL 93.365903 102.902006 \nL 93.388733 102.850108 \nL 93.434392 102.956996 \nL 93.54854 103.223091 \nL 93.594199 103.119462 \nL 93.845324 102.762145 \nL 93.868154 102.815043 \nL 93.913813 102.712749 \nL 93.936642 102.765584 \nL 94.07362 102.667181 \nL 94.164938 102.7741 \nL 94.187767 102.723337 \nL 94.393233 102.474486 \nL 94.461722 102.426278 \nL 94.530211 102.582877 \nL 94.644359 102.536604 \nL 94.712847 102.590437 \nL 94.735677 102.540484 \nL 94.758506 102.490583 \nL 94.804165 102.594191 \nL 94.826995 102.64591 \nL 94.872654 102.546277 \nL 94.986802 102.399361 \nL 95.009631 102.450944 \nL 95.192268 102.660273 \nL 95.374904 102.467021 \nL 95.511882 102.572805 \nL 95.740177 102.284262 \nL 95.808666 102.237978 \nL 95.877155 102.389709 \nL 95.945643 102.244634 \nL 96.014132 102.297247 \nL 96.219598 102.650253 \nL 96.242427 102.602097 \nL 96.265257 102.554005 \nL 96.310916 102.653743 \nL 96.333746 102.703528 \nL 96.379405 102.607481 \nL 96.493553 102.465748 \nL 96.516382 102.515418 \nL 96.6077 102.616365 \nL 96.63053 102.568683 \nL 96.721848 102.475379 \nL 96.744678 102.524775 \nL 96.927314 102.725083 \nL 96.950144 102.677705 \nL 96.995803 102.775677 \nL 97.13278 102.876362 \nL 97.15561 102.829132 \nL 97.201269 102.926462 \nL 97.224098 102.975049 \nL 97.269757 102.880736 \nL 97.452394 102.696021 \nL 97.498053 102.792815 \nL 97.566542 102.747625 \nL 97.772008 102.518393 \nL 97.931815 102.666024 \nL 97.954644 102.619782 \nL 98.000303 102.715525 \nL 98.023133 102.669336 \nL 98.18294 102.909177 \nL 98.205769 102.863072 \nL 98.251428 102.77103 \nL 98.319917 102.819995 \nL 98.342747 102.867383 \nL 98.388406 102.775625 \nL 98.411235 102.82296 \nL 98.571042 102.596115 \nL 98.593872 102.643345 \nL 98.66236 102.692131 \nL 98.68519 102.646657 \nL 98.708019 102.601225 \nL 98.753679 102.695327 \nL 98.776508 102.742305 \nL 98.822167 102.651588 \nL 98.981974 102.519424 \nL 99.141781 102.662996 \nL 99.324417 102.395797 \nL 99.347247 102.442323 \nL 99.370077 102.488806 \nL 99.415736 102.399572 \nL 99.438565 102.355023 \nL 99.484224 102.447822 \nL 99.644031 102.590016 \nL 99.826668 102.416321 \nL 99.986475 102.647403 \nL 100.009304 102.603296 \nL 100.054963 102.515218 \nL 100.100622 102.606587 \nL 100.21477 102.744786 \nL 100.2376 102.700847 \nL 100.420236 102.528981 \nL 100.443066 102.574308 \nL 100.488725 102.487103 \nL 100.511554 102.532388 \nL 100.557214 102.445351 \nL 100.602873 102.535784 \nL 100.671361 102.582572 \nL 100.694191 102.539159 \nL 100.808339 102.322754 \nL 100.853998 102.412799 \nL 100.922486 102.459524 \nL 100.945316 102.416405 \nL 101.105123 102.29117 \nL 101.173612 102.250269 \nL 101.287759 102.473466 \nL 101.379078 102.302609 \nL 101.447566 102.348956 \nL 101.561714 102.570586 \nL 101.607373 102.485484 \nL 101.698691 102.402337 \nL 101.721521 102.446486 \nL 101.79001 102.492286 \nL 101.812839 102.449956 \nL 101.949816 102.369049 \nL 102.086794 102.54613 \nL 102.109623 102.504052 \nL 102.132453 102.462005 \nL 102.178112 102.549379 \nL 102.200942 102.507374 \nL 102.315089 102.639665 \nL 102.337919 102.597734 \nL 102.452067 102.473886 \nL 102.474896 102.5173 \nL 102.520555 102.60399 \nL 102.566214 102.52058 \nL 102.79451 102.190475 \nL 102.81734 102.233699 \nL 102.840169 102.276902 \nL 102.885828 102.194354 \nL 102.908658 102.237505 \nL 103.228272 101.831686 \nL 103.273931 101.917672 \nL 103.342419 101.879147 \nL 103.479397 101.719057 \nL 103.502226 101.761903 \nL 103.639204 101.851936 \nL 103.776181 101.77575 \nL 103.79901 101.818312 \nL 103.84467 101.737825 \nL 103.867499 101.780334 \nL 104.027306 101.582246 \nL 104.050136 101.624671 \nL 104.095795 101.709405 \nL 104.141454 101.629507 \nL 104.232772 101.552249 \nL 104.255602 101.594516 \nL 104.415408 101.725702 \nL 104.529556 101.690679 \nL 104.552386 101.732621 \nL 104.598045 101.653438 \nL 104.803511 101.461216 \nL 104.917659 101.508026 \nL 105.077466 101.39566 \nL 105.397079 101.814548 \nL 105.511227 101.620002 \nL 105.579716 101.663479 \nL 105.693864 101.868528 \nL 105.739523 101.791017 \nL 105.808011 101.754532 \nL 105.830841 101.795391 \nL 106.059136 102.043685 \nL 106.127625 102.007095 \nL 106.150455 102.047586 \nL 106.287432 102.132194 \nL 106.40158 102.097539 \nL 106.515728 102.141478 \nL 106.652705 102.068783 \nL 106.744023 102.150678 \nL 106.766853 102.112564 \nL 106.812512 102.036441 \nL 106.881 102.078277 \nL 107.086466 102.280687 \nL 107.109296 102.242773 \nL 107.154955 102.321976 \nL 107.177785 102.361531 \nL 107.223444 102.285786 \nL 107.314762 102.211945 \nL 107.337592 102.251426 \nL 107.360421 102.290865 \nL 107.40608 102.215456 \nL 107.565887 102.029407 \nL 107.588717 102.068783 \nL 107.794183 102.345034 \nL 107.817012 102.307593 \nL 107.839842 102.270194 \nL 107.885501 102.348283 \nL 108.090967 102.545793 \nL 108.159456 102.509961 \nL 108.182285 102.548685 \nL 108.250774 102.588776 \nL 108.273603 102.551555 \nL 108.479069 102.369122 \nL 108.501899 102.407668 \nL 108.547558 102.333773 \nL 108.684535 102.263349 \nL 109.049808 102.725083 \nL 109.255274 102.544605 \nL 109.415081 102.660914 \nL 109.643377 102.445645 \nL 109.689036 102.521001 \nL 109.734695 102.448621 \nL 109.803184 102.340271 \nL 109.848843 102.41549 \nL 109.96299 102.529496 \nL 109.98582 102.493475 \nL 110.122797 102.42449 \nL 110.145627 102.461858 \nL 110.191286 102.390119 \nL 110.259775 102.282748 \nL 110.305434 102.357388 \nL 110.442411 102.434868 \nL 110.579388 102.366599 \nL 110.739195 102.480637 \nL 110.944661 102.306531 \nL 110.99032 102.380246 \nL 111.03598 102.309664 \nL 111.127298 102.312776 \nL 111.424082 102.644995 \nL 111.5154 102.64755 \nL 111.53823 102.683909 \nL 111.583889 102.613768 \nL 111.698037 102.581384 \nL 111.903503 102.764784 \nL 111.926332 102.729898 \nL 111.971991 102.801994 \nL 112.086139 102.910975 \nL 112.108969 102.87613 \nL 112.268776 102.7741 \nL 112.382923 102.812183 \nL 112.405753 102.777559 \nL 112.451412 102.849014 \nL 112.588389 102.922425 \nL 112.611219 102.887885 \nL 112.656878 102.959004 \nL 112.748196 103.030942 \nL 112.771026 102.996456 \nL 112.930833 102.895256 \nL 113.136299 103.073641 \nL 113.159128 103.039375 \nL 113.204787 103.109694 \nL 113.387424 103.251532 \nL 113.501572 103.218906 \nL 113.638549 103.359008 \nL 113.661378 103.324921 \nL 113.707038 103.25682 \nL 113.752697 103.326309 \nL 113.821185 103.361689 \nL 113.844015 103.327707 \nL 113.980992 103.261299 \nL 114.232117 103.504032 \nL 114.346265 103.471385 \nL 114.460413 103.506797 \nL 114.551731 103.372246 \nL 114.59739 103.440673 \nL 114.780027 103.578178 \nL 114.917004 103.444836 \nL 114.939834 103.478818 \nL 115.076811 103.547739 \nL 115.236618 103.448958 \nL 115.327936 103.51708 \nL 115.350766 103.483886 \nL 115.442084 103.418183 \nL 115.464913 103.451881 \nL 115.487743 103.485558 \nL 115.533402 103.419392 \nL 115.62472 103.420601 \nL 115.738868 103.521843 \nL 115.761698 103.48888 \nL 115.898675 103.424207 \nL 115.921504 103.457653 \nL 115.967164 103.391992 \nL 116.218289 103.164505 \nL 116.241118 103.197867 \nL 116.286777 103.132741 \nL 116.332436 103.0677 \nL 116.378096 103.134361 \nL 116.492243 103.234887 \nL 116.515073 103.20243 \nL 116.67488 103.106855 \nL 116.766198 103.239272 \nL 116.811857 103.174662 \nL 116.926005 103.143992 \nL 117.085812 103.24434 \nL 117.19996 103.21367 \nL 117.291278 103.279983 \nL 117.314107 103.247925 \nL 117.451085 103.185397 \nL 117.565232 103.219558 \nL 117.588062 103.187668 \nL 117.610892 103.155799 \nL 117.656551 103.221019 \nL 117.725039 103.254307 \nL 117.770698 103.190675 \nL 117.953335 103.065377 \nL 118.090312 103.1319 \nL 118.113142 103.100305 \nL 118.318608 102.944515 \nL 118.478415 102.979538 \nL 118.661051 102.856248 \nL 118.72954 102.952758 \nL 118.798028 102.859181 \nL 118.843688 102.796906 \nL 118.889347 102.861137 \nL 118.980665 102.863072 \nL 119.003494 102.832013 \nL 119.071983 102.738972 \nL 119.117642 102.803004 \nL 119.345938 102.933549 \nL 119.437256 102.935378 \nL 119.619893 103.001513 \nL 119.779699 102.911027 \nL 120.122143 103.196942 \nL 120.190631 103.167049 \nL 120.236291 103.229683 \nL 120.396097 103.262982 \nL 120.533075 103.26499 \nL 120.692882 103.298047 \nL 121.080984 102.845219 \nL 121.103814 102.876236 \nL 121.28645 102.940856 \nL 121.537575 102.793993 \nL 121.674553 102.796927 \nL 121.81153 102.79986 \nL 121.948507 102.863072 \nL 121.971337 102.833401 \nL 122.085485 102.865858 \nL 122.268121 102.929564 \nL 122.450757 102.873207 \nL 122.587735 102.875941 \nL 122.793201 102.790692 \nL 122.907349 102.822834 \nL 122.930178 102.793583 \nL 122.975837 102.735155 \nL 123.044326 102.825651 \nL 123.204133 102.97691 \nL 123.249792 102.918587 \nL 123.34111 102.920332 \nL 123.36394 102.950298 \nL 123.592235 103.072253 \nL 123.729213 103.015802 \nL 123.752042 103.045568 \nL 123.911849 103.077584 \nL 124.003167 103.079108 \nL 124.025997 103.108727 \nL 124.254292 103.228989 \nL 124.551077 103.03007 \nL 124.665224 103.061003 \nL 124.688054 103.032414 \nL 124.733713 102.975301 \nL 124.802202 103.063274 \nL 124.984838 103.239356 \nL 125.030497 103.182348 \nL 125.121815 103.126139 \nL 125.167475 103.184388 \nL 125.304452 103.186406 \nL 125.441429 103.188425 \nL 125.555577 103.218706 \nL 125.578407 103.190433 \nL 125.852361 103.023488 \nL 125.875191 103.052349 \nL 125.943679 102.96813 \nL 126.012168 102.884069 \nL 126.080657 102.970549 \nL 126.149145 103.000125 \nL 126.194805 102.9442 \nL 126.377441 102.777812 \nL 126.4231 102.835251 \nL 126.605737 102.895172 \nL 126.651396 102.839678 \nL 126.719884 102.925421 \nL 126.788373 102.954777 \nL 126.834032 102.899388 \nL 126.94818 102.873439 \nL 126.971009 102.901911 \nL 127.085157 102.932003 \nL 127.107987 102.904414 \nL 127.244964 102.795171 \nL 127.290623 102.851906 \nL 127.496089 102.995005 \nL 127.518919 102.967552 \nL 127.655896 102.803246 \nL 127.724385 102.887843 \nL 127.838533 102.917641 \nL 127.861362 102.890356 \nL 127.998339 102.892848 \nL 128.226635 103.117496 \nL 128.272294 103.063095 \nL 128.614737 102.82174 \nL 128.774544 102.906853 \nL 128.797374 102.879905 \nL 128.911522 102.854671 \nL 128.934351 102.882397 \nL 129.162647 103.049805 \nL 129.185476 103.022962 \nL 129.413772 102.863913 \nL 129.436601 102.891439 \nL 129.550749 102.866405 \nL 129.710556 102.842296 \nL 129.893193 102.899556 \nL 129.984511 102.847342 \nL 130.03017 102.901975 \nL 130.212806 103.012511 \nL 130.235636 102.986057 \nL 130.395443 102.908378 \nL 130.418272 102.935536 \nL 130.55525 103.044716 \nL 130.600909 102.992029 \nL 130.715057 102.967237 \nL 130.737886 102.994258 \nL 130.897693 103.023435 \nL 130.989011 102.971758 \nL 131.03467 103.025601 \nL 131.148818 103.106897 \nL 131.194477 103.054599 \nL 131.491261 102.874438 \nL 131.696727 103.009619 \nL 131.719557 102.98367 \nL 131.765216 102.931835 \nL 131.833705 103.011785 \nL 131.925023 103.013215 \nL 131.947853 102.98735 \nL 132.153319 102.859854 \nL 132.176148 102.886413 \nL 132.335955 102.915265 \nL 132.495762 102.891923 \nL 132.792546 103.13047 \nL 132.815376 103.104858 \nL 132.929523 103.028808 \nL 132.975183 103.081264 \nL 133.203478 103.187815 \nL 133.454603 103.062517 \nL 133.660069 103.142509 \nL 133.819876 103.0679 \nL 133.842706 103.093828 \nL 134.093831 103.224973 \nL 134.253638 103.150605 \nL 134.276467 103.176365 \nL 134.459104 103.280351 \nL 134.481933 103.255233 \nL 134.687399 103.181759 \nL 134.870036 103.285198 \nL 134.892865 103.260206 \nL 135.098331 103.136705 \nL 135.121161 103.162202 \nL 135.303797 103.214868 \nL 135.440775 103.116245 \nL 135.486434 103.167018 \nL 135.714729 103.270005 \nL 135.806047 103.271078 \nL 135.828877 103.296312 \nL 136.034343 103.37336 \nL 136.262639 103.22676 \nL 136.285468 103.251858 \nL 136.445275 103.278543 \nL 136.742059 103.109169 \nL 136.879037 103.16032 \nL 136.901866 103.13598 \nL 137.016014 103.162097 \nL 137.244309 103.263171 \nL 137.289969 103.214658 \nL 137.358457 103.289004 \nL 137.541094 103.339956 \nL 137.655241 103.316762 \nL 137.678071 103.341418 \nL 137.792219 103.366999 \nL 137.815048 103.342869 \nL 138.089003 103.200064 \nL 138.134662 103.249166 \nL 138.203151 103.177217 \nL 138.340128 103.178931 \nL 138.499935 103.205101 \nL 138.819549 103.016401 \nL 138.956526 103.018367 \nL 139.161992 102.901438 \nL 139.184822 102.925758 \nL 139.207651 102.950077 \nL 139.27614 102.879285 \nL 139.458776 102.83441 \nL 139.572924 102.907852 \nL 139.618583 102.860874 \nL 139.869708 102.746038 \nL 140.120834 102.868907 \nL 140.257811 102.776424 \nL 140.30347 102.824505 \nL 140.508936 102.94584 \nL 140.531766 102.922593 \nL 140.80572 102.785666 \nL 141.011186 102.859465 \nL 141.262311 102.699712 \nL 141.285141 102.723495 \nL 141.3308 102.77103 \nL 141.399289 102.70213 \nL 141.490607 102.657076 \nL 141.536266 102.704538 \nL 141.581925 102.751947 \nL 141.650414 102.683257 \nL 141.901539 102.571616 \nL 142.107005 102.644995 \nL 142.403789 102.488775 \nL 142.426619 102.512306 \nL 142.495107 102.444468 \nL 142.86038 102.176312 \nL 142.88321 102.199801 \nL 142.928869 102.246747 \nL 142.997358 102.179498 \nL 143.157164 102.114551 \nL 143.179994 102.137977 \nL 143.545267 102.374432 \nL 143.682244 102.377281 \nL 143.796392 102.356936 \nL 143.88771 102.40425 \nL 144.024688 102.407047 \nL 144.184494 102.38768 \nL 144.344301 102.413545 \nL 144.572597 102.328075 \nL 144.709574 102.330966 \nL 144.892211 102.289918 \nL 145.097677 102.36151 \nL 145.303143 102.298719 \nL 145.485779 102.3472 \nL 145.736904 102.241227 \nL 145.896711 102.266903 \nL 146.056518 102.248187 \nL 146.239154 102.296364 \nL 146.421791 102.256073 \nL 146.513109 102.213953 \nL 146.604427 102.259995 \nL 146.809893 102.330314 \nL 146.9697 102.311672 \nL 147.106678 102.314511 \nL 147.334973 102.231838 \nL 147.449121 102.212481 \nL 147.631757 102.172884 \nL 147.791564 102.198161 \nL 148.01986 102.116381 \nL 148.179667 102.141646 \nL 148.453621 102.01824 \nL 148.613428 102.043548 \nL 148.796065 102.004782 \nL 148.955872 102.030027 \nL 149.184167 101.949677 \nL 149.412463 102.040636 \nL 149.54944 102.043801 \nL 149.800565 102.155967 \nL 149.937542 102.158953 \nL 150.05169 102.140216 \nL 150.257156 102.081179 \nL 150.394134 102.084249 \nL 150.57677 102.046135 \nL 150.759406 102.092419 \nL 150.873554 102.115992 \nL 151.033361 102.1405 \nL 151.193168 102.122994 \nL 151.467123 102.254422 \nL 151.6041 102.257219 \nL 151.695418 102.217349 \nL 151.900884 102.159153 \nL 152.060691 102.183335 \nL 152.266157 102.125433 \nL 152.540112 102.2554 \nL 152.63143 102.298561 \nL 152.791237 102.322334 \nL 152.951044 102.304849 \nL 153.065192 102.286512 \nL 153.247828 102.24905 \nL 153.544612 102.398278 \nL 153.704419 102.380793 \nL 153.841396 102.383348 \nL 154.046862 102.326077 \nL 154.18384 102.328695 \nL 154.457794 102.212229 \nL 154.754579 102.359754 \nL 154.891556 102.362309 \nL 155.165511 102.488217 \nL 155.348147 102.451176 \nL 155.462295 102.433112 \nL 155.644931 102.396281 \nL 155.918886 102.521159 \nL 156.033034 102.543039 \nL 156.2385 102.606219 \nL 156.443966 102.549852 \nL 156.626602 102.59255 \nL 156.969046 102.420001 \nL 157.174512 102.482845 \nL 157.402807 102.407941 \nL 157.516955 102.390288 \nL 157.631103 102.411978 \nL 157.836569 102.474433 \nL 157.973546 102.476767 \nL 158.110523 102.47908 \nL 158.224671 102.500551 \nL 158.384478 102.522725 \nL 158.589944 102.467683 \nL 158.77258 102.509645 \nL 158.978046 102.454835 \nL 159.183512 102.516396 \nL 159.343319 102.499688 \nL 159.571615 102.580596 \nL 159.731422 102.563846 \nL 159.868399 102.566012 \nL 160.188013 102.417656 \nL 160.302161 102.400455 \nL 160.530456 102.327949 \nL 160.690263 102.349902 \nL 160.85007 102.333679 \nL 161.078366 102.413787 \nL 161.192513 102.434731 \nL 161.35232 102.45638 \nL 161.489298 102.458651 \nL 161.671934 102.499489 \nL 161.923059 102.409224 \nL 162.128525 102.469176 \nL 162.265503 102.471416 \nL 162.470969 102.531063 \nL 162.607946 102.533218 \nL 162.699264 102.497197 \nL 162.836241 102.499394 \nL 162.950389 102.482529 \nL 163.133026 102.448169 \nL 163.338492 102.507374 \nL 163.543958 102.454887 \nL 163.840742 102.589407 \nL 163.93206 102.627805 \nL 164.069037 102.629813 \nL 164.183185 102.649948 \nL 164.502799 102.801879 \nL 164.639776 102.803645 \nL 164.776754 102.805422 \nL 165.073538 102.680986 \nL 165.279004 102.73872 \nL 165.438811 102.722612 \nL 165.598618 102.743009 \nL 165.781254 102.709038 \nL 165.872572 102.67391 \nL 166.078038 102.622306 \nL 166.283504 102.679629 \nL 166.5118 102.610446 \nL 166.625948 102.594022 \nL 166.740095 102.613737 \nL 166.991221 102.707387 \nL 167.242346 102.620939 \nL 167.470641 102.695906 \nL 167.607619 102.697767 \nL 167.813085 102.754176 \nL 167.972891 102.738394 \nL 168.087039 102.722065 \nL 168.269676 102.688871 \nL 168.383823 102.672627 \nL 168.56646 102.639612 \nL 168.657778 102.605399 \nL 168.817585 102.589943 \nL 168.931733 102.573888 \nL 169.182858 102.489206 \nL 169.342665 102.473992 \nL 169.456813 102.493348 \nL 169.639449 102.496103 \nL 169.867745 102.429316 \nL 170.073211 102.45004 \nL 170.347165 102.349356 \nL 170.484143 102.316656 \nL 170.643949 102.301852 \nL 170.940734 102.393736 \nL 171.054881 102.412904 \nL 171.306007 102.468829 \nL 171.420154 102.48787 \nL 171.62562 102.508215 \nL 171.853916 102.477051 \nL 172.105041 102.532451 \nL 172.333337 102.501371 \nL 172.561632 102.539022 \nL 172.858416 102.457716 \nL 173.269348 102.634345 \nL 173.497644 102.60337 \nL 173.611792 102.553921 \nL 173.817258 102.539842 \nL 174.068383 102.594191 \nL 174.251019 102.596682 \nL 174.524974 102.667896 \nL 174.776099 102.620644 \nL 174.958735 102.623084 \nL 175.095713 102.658496 \nL 175.278349 102.660862 \nL 175.552304 102.597513 \nL 175.780599 102.633966 \nL 175.986065 102.620003 \nL 176.328509 102.740854 \nL 176.602463 102.677863 \nL 177.036225 102.865112 \nL 177.196032 102.883385 \nL 177.333009 102.851916 \nL 177.492816 102.870169 \nL 177.721112 102.905539 \nL 178.040725 102.810637 \nL 178.246191 102.829353 \nL 178.474487 102.799261 \nL 178.725612 102.851043 \nL 179.022396 102.773028 \nL 179.159374 102.742147 \nL 179.410499 102.696515 \nL 179.684454 102.764553 \nL 179.821431 102.798462 \nL 180.026897 102.816925 \nL 180.36934 102.708186 \nL 180.757443 102.857152 \nL 180.962909 102.843379 \nL 181.305352 102.958857 \nL 181.487988 102.960686 \nL 181.693454 102.978644 \nL 181.876091 102.980432 \nL 182.081557 102.998306 \nL 182.332682 102.95321 \nL 182.44683 102.906885 \nL 182.652296 102.893206 \nL 182.903421 102.943106 \nL 183.108887 102.929417 \nL 183.405671 103.010923 \nL 183.656796 102.966269 \nL 183.885092 102.999778 \nL 184.181876 102.924549 \nL 184.364512 102.926378 \nL 184.50149 102.958888 \nL 184.912422 103.118085 \nL 185.117888 103.104332 \nL 185.346183 103.137221 \nL 185.642968 103.062517 \nL 185.825604 103.064136 \nL 186.122388 102.989874 \nL 186.350684 103.02271 \nL 186.53332 103.024382 \nL 186.784445 103.072558 \nL 186.989911 103.059068 \nL 187.195377 103.076133 \nL 187.469332 103.017621 \nL 187.629139 103.003868 \nL 187.788946 103.020512 \nL 188.017241 103.052896 \nL 188.199878 103.054494 \nL 188.382514 103.056093 \nL 188.61081 103.027904 \nL 188.861935 103.075323 \nL 188.976083 103.121449 \nL 189.318526 103.229325 \nL 189.683799 103.11226 \nL 189.957754 103.174273 \nL 190.186049 103.14621 \nL 190.345856 103.132584 \nL 190.551322 103.119357 \nL 190.848106 103.195974 \nL 191.030743 103.197352 \nL 191.16772 103.168763 \nL 191.373186 103.155568 \nL 191.715629 103.261468 \nL 191.898266 103.26275 \nL 192.012414 103.2194 \nL 192.19505 103.220735 \nL 192.514664 103.311021 \nL 192.765789 103.268785 \nL 192.925596 103.255264 \nL 193.336528 103.112396 \nL 193.656142 103.202199 \nL 193.975755 103.117496 \nL 194.135562 103.104279 \nL 194.318199 103.105741 \nL 194.592153 103.165704 \nL 194.797619 103.152834 \nL 195.025915 103.183368 \nL 195.368358 103.085364 \nL 195.573824 103.101367 \nL 195.870608 103.032173 \nL 196.144563 103.09161 \nL 196.30437 103.10716 \nL 196.646813 103.209475 \nL 196.897938 103.168648 \nL 197.217552 103.256063 \nL 197.559996 103.159395 \nL 197.742632 103.160751 \nL 197.925268 103.162108 \nL 198.153564 103.191958 \nL 198.450348 103.123825 \nL 198.701473 103.167828 \nL 198.975428 103.113826 \nL 199.249383 103.171833 \nL 199.546167 103.104248 \nL 199.728803 103.105657 \nL 199.88861 103.120808 \nL 200.094076 103.136253 \nL 200.368031 103.08283 \nL 200.527838 103.070224 \nL 200.733304 103.058017 \nL 200.984429 103.101451 \nL 201.189895 103.089233 \nL 201.577997 103.216004 \nL 201.737804 103.23084 \nL 201.920441 103.23207 \nL 202.034589 103.273969 \nL 202.171566 103.247463 \nL 202.46835 103.181065 \nL 202.650987 103.182348 \nL 202.924941 103.129766 \nL 203.039089 103.089759 \nL 203.198896 103.104574 \nL 203.381532 103.105951 \nL 203.632657 103.067143 \nL 203.860953 103.096005 \nL 203.99793 103.124099 \nL 204.317544 103.207445 \nL 204.659987 103.115477 \nL 204.842624 103.116823 \nL 205.002431 103.131438 \nL 205.322045 103.214227 \nL 205.824295 103.030459 \nL 206.098249 103.085985 \nL 206.303715 103.074198 \nL 206.57767 103.129472 \nL 206.988602 102.999789 \nL 207.125579 102.974386 \nL 207.376705 102.936756 \nL 207.605 102.965092 \nL 207.719148 103.005635 \nL 207.924614 103.020449 \nL 208.038762 103.060855 \nL 208.289887 103.102208 \nL 208.65516 102.999915 \nL 208.883455 103.027935 \nL 209.020433 103.055167 \nL 209.15741 103.030049 \nL 209.362876 103.018578 \nL 209.522683 103.006781 \nL 209.979274 102.854271 \nL 210.16191 102.85588 \nL 210.367376 102.844714 \nL 210.641331 102.898946 \nL 210.823967 102.900492 \nL 211.143581 102.980653 \nL 211.417536 102.931278 \nL 211.645831 102.958899 \nL 211.896957 102.922372 \nL 212.125252 102.94992 \nL 212.536184 102.825283 \nL 212.76448 102.852852 \nL 212.901457 102.879579 \nL 213.129753 102.881514 \nL 213.335219 102.870516 \nL 213.609173 102.898273 \nL 213.837469 102.874795 \nL 214.179912 102.941003 \nL 214.385378 102.955303 \nL 214.568015 102.98202 \nL 214.933287 103.060466 \nL 215.161583 103.062128 \nL 215.412708 103.076501 \nL 215.777981 103.003879 \nL 216.074765 103.043665 \nL 216.303061 103.045336 \nL 216.462868 103.009041 \nL 216.713993 102.998464 \nL 217.079266 103.075838 \nL 217.307561 103.077447 \nL 217.581516 103.104174 \nL 217.741323 103.142425 \nL 217.992448 103.156451 \nL 218.152255 103.194565 \nL 218.357721 103.183515 \nL 218.608846 103.17279 \nL 218.90563 103.211577 \nL 219.179585 103.188709 \nL 219.499199 103.239724 \nL 219.795983 103.204806 \nL 220.161256 103.280278 \nL 220.503699 103.221324 \nL 220.731995 103.222701 \nL 220.96029 103.224079 \nL 221.234245 103.249965 \nL 221.599518 103.179509 \nL 221.827813 103.180928 \nL 222.261575 103.075176 \nL 222.421382 103.040142 \nL 222.672507 103.029891 \nL 223.060609 103.116602 \nL 223.311734 103.106277 \nL 223.54003 103.107781 \nL 223.722666 103.132878 \nL 223.996621 103.158501 \nL 224.316235 103.112891 \nL 224.613019 103.150479 \nL 224.749996 103.198834 \nL 225.06961 103.248167 \nL 225.343565 103.226066 \nL 225.61752 103.25129 \nL 225.845815 103.252583 \nL 226.188258 103.313387 \nL 226.348065 103.349524 \nL 226.59919 103.362552 \nL 226.850316 103.352079 \nL 227.215588 103.424144 \nL 227.535202 103.378891 \nL 227.67218 103.332859 \nL 227.968964 103.299424 \nL 228.265748 103.335909 \nL 228.539703 103.31407 \nL 228.813657 103.338695 \nL 229.019123 103.351322 \nL 229.247419 103.352458 \nL 229.612692 103.285019 \nL 229.795328 103.262929 \nL 230.023624 103.26418 \nL 230.251919 103.265431 \nL 230.594363 103.209906 \nL 230.799829 103.199623 \nL 230.982465 103.223585 \nL 231.347738 103.29423 \nL 231.553204 103.306721 \nL 231.827159 103.330935 \nL 232.055454 103.332081 \nL 232.329409 103.356191 \nL 232.603364 103.334826 \nL 232.968636 103.404588 \nL 233.265421 103.372035 \nL 233.744841 103.498343 \nL 233.995966 103.488092 \nL 234.269921 103.511707 \nL 234.475387 103.523746 \nL 234.726512 103.535932 \nL 234.909149 103.559032 \nL 235.160274 103.571144 \nL 235.36574 103.583057 \nL 235.571206 103.572616 \nL 235.822331 103.562375 \nL 236.096286 103.585633 \nL 236.324581 103.586432 \nL 236.621365 103.62075 \nL 237.009468 103.544522 \nL 237.39757 103.623305 \nL 237.648695 103.613096 \nL 237.876991 103.613853 \nL 238.128116 103.603675 \nL 238.539048 103.69291 \nL 238.698855 103.726282 \nL 238.92715 103.726892 \nL 239.406571 103.607954 \nL 239.749015 103.663638 \nL 240.00014 103.653502 \nL 240.319753 103.697978 \nL 240.50239 103.720226 \nL 240.822004 103.76447 \nL 241.073129 103.75425 \nL 241.255765 103.733064 \nL 241.52972 103.712172 \nL 241.849334 103.756184 \nL 242.077629 103.756752 \nL 242.328754 103.768129 \nL 242.55705 103.768686 \nL 242.899493 103.823139 \nL 243.264766 103.759675 \nL 243.493062 103.760232 \nL 243.767016 103.739551 \nL 244.08663 103.782996 \nL 244.383414 103.751758 \nL 244.61171 103.752326 \nL 244.885665 103.73177 \nL 245.250937 103.796265 \nL 245.593381 103.744156 \nL 245.981483 103.818997 \nL 246.460904 103.704212 \nL 246.849006 103.77879 \nL 247.008813 103.810648 \nL 247.328427 103.853242 \nL 247.533893 103.864103 \nL 247.6937 103.833023 \nL 247.967655 103.812678 \nL 248.241609 103.834116 \nL 248.469905 103.834579 \nL 248.606882 103.793205 \nL 248.903666 103.762682 \nL 249.109132 103.752788 \nL 249.405917 103.722402 \nL 249.634212 103.72298 \nL 249.862508 103.723569 \nL 250.182121 103.765679 \nL 250.410417 103.766215 \nL 250.638713 103.766741 \nL 250.867008 103.767267 \nL 251.140963 103.788453 \nL 251.392088 103.778748 \nL 251.574724 103.758645 \nL 251.871509 103.728637 \nL 252.191122 103.770316 \nL 252.510736 103.730225 \nL 252.670543 103.700038 \nL 252.967327 103.670272 \nL 253.172793 103.660673 \nL 253.35543 103.681512 \nL 253.560896 103.671923 \nL 253.789191 103.672554 \nL 254.040316 103.663123 \nL 254.314271 103.643661 \nL 254.725203 103.70539 \nL 255.021987 103.696074 \nL 255.364431 103.727155 \nL 255.615556 103.737816 \nL 256.003658 103.788873 \nL 256.209124 103.819365 \nL 256.41459 103.789757 \nL 256.711374 103.780399 \nL 256.93967 103.760937 \nL 257.236454 103.751642 \nL 257.556068 103.772282 \nL 258.058318 103.674142 \nL 258.309443 103.66491 \nL 258.560568 103.675498 \nL 258.948671 103.725935 \nL 259.199796 103.736418 \nL 259.49658 103.746974 \nL 259.861853 103.708471 \nL 260.02166 103.659716 \nL 260.341274 103.640959 \nL 260.729376 103.691038 \nL 261.140308 103.633431 \nL 261.596899 103.712771 \nL 261.893684 103.70375 \nL 262.144809 103.694655 \nL 262.57857 103.627795 \nL 262.898184 103.648087 \nL 263.194968 103.639224 \nL 263.514582 103.659443 \nL 264.085321 103.535679 \nL 264.541912 103.614116 \nL 264.793037 103.624441 \nL 265.089821 103.634881 \nL 265.477924 103.588082 \nL 265.706219 103.56964 \nL 266.094322 103.523104 \nL 266.436765 103.552828 \nL 266.665061 103.572595 \nL 266.893356 103.554269 \nL 267.2358 103.526858 \nL 267.601072 103.56596 \nL 267.989175 103.519845 \nL 268.194641 103.492171 \nL 268.605573 103.436961 \nL 268.970846 103.475979 \nL 269.29046 103.458273 \nL 269.495926 103.430821 \nL 269.861198 103.394652 \nL 270.112324 103.38624 \nL 270.546085 103.322482 \nL 270.979847 103.389594 \nL 271.367949 103.34452 \nL 271.664733 103.355023 \nL 271.938688 103.356117 \nL 272.144154 103.329095 \nL 272.37245 103.348568 \nL 272.646404 103.349661 \nL 272.943188 103.341607 \nL 273.171484 103.324048 \nL 273.673734 103.233962 \nL 273.947689 103.235192 \nL 274.312962 103.200085 \nL 274.792382 103.28482 \nL 275.203314 103.23166 \nL 275.500099 103.242132 \nL 275.842542 103.216277 \nL 276.093667 103.208297 \nL 276.43611 103.182569 \nL 276.710065 103.183851 \nL 277.052508 103.158228 \nL 277.440611 103.205374 \nL 277.783054 103.179803 \nL 278.125498 103.208486 \nL 278.467941 103.182989 \nL 279.061509 103.311652 \nL 279.335464 103.312756 \nL 279.54093 103.28667 \nL 279.860544 103.270068 \nL 280.111669 103.262183 \nL 280.317135 103.289888 \nL 280.659578 103.318087 \nL 280.865044 103.345676 \nL 281.344465 103.427656 \nL 281.61842 103.428613 \nL 281.938033 103.447486 \nL 282.166329 103.466001 \nL 282.691409 103.565098 \nL 283.12517 103.504505 \nL 283.467614 103.532041 \nL 283.467614 103.532041 \n\" clip-path=\"url(#p74268483fb)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 192.42 \nL 55.217716 192.42 \nL 55.309034 74.819996 \nL 55.354693 82.17 \nL 55.446011 118.920002 \nL 55.5145 110.1 \nL 55.651477 91.619995 \nL 55.674307 96.201815 \nL 55.765625 111.004615 \nL 55.834114 107.261381 \nL 56.01675 97.068653 \nL 56.085239 90.990002 \nL 56.130898 95.820001 \nL 56.199387 102.259995 \nL 56.245046 98.590213 \nL 56.336364 99.03176 \nL 56.404853 94.419995 \nL 56.54183 98.339995 \nL 56.587489 95.684514 \nL 56.655978 97.43538 \nL 56.815785 101.769999 \nL 56.884273 98.339995 \nL 56.952762 99.696923 \nL 56.998421 102.015002 \nL 57.04408 99.917565 \nL 57.181058 94.197272 \nL 57.249546 95.496918 \nL 57.409353 98.820003 \nL 57.432183 97.983635 \nL 57.477842 99.853659 \nL 57.728967 105.794999 \nL 57.774626 104.22 \nL 57.820285 105.740688 \nL 57.843115 106.481538 \nL 57.888774 104.961176 \nL 58.09424 101.46375 \nL 58.299706 106.151385 \nL 58.322535 105.498261 \nL 58.391024 103.594465 \nL 58.436683 104.836782 \nL 58.573661 107.179732 \nL 58.59649 106.571998 \nL 58.61932 105.972317 \nL 58.664979 107.102353 \nL 58.687808 106.51091 \nL 58.710638 107.065164 \nL 58.779127 106.452913 \nL 58.961763 102.0947 \nL 59.007422 103.170004 \nL 59.12157 105.749478 \nL 59.167229 104.724001 \nL 59.304206 103.732706 \nL 59.327036 104.22 \nL 59.372695 103.261299 \nL 59.418354 102.323228 \nL 59.464013 103.281697 \nL 59.509672 104.22 \nL 59.555331 103.301254 \nL 59.62382 101.958456 \nL 59.715138 102.00392 \nL 59.943434 104.642011 \nL 60.103241 103.403336 \nL 60.217389 103.8209 \nL 60.263048 103.033455 \nL 60.354366 103.054358 \nL 60.377196 103.446319 \nL 60.422855 102.686085 \nL 60.765298 97.380001 \nL 60.810957 97.43538 \nL 60.970764 98.664097 \nL 61.336037 93.766671 \nL 61.358866 94.130706 \nL 61.427355 93.919275 \nL 61.473014 94.633046 \nL 61.518673 94.067484 \nL 61.587162 94.489747 \nL 61.655651 94.903094 \nL 61.67848 94.626317 \nL 61.70131 94.351463 \nL 61.746969 95.032504 \nL 61.861117 96.092351 \nL 61.883946 95.820001 \nL 62.089412 94.614057 \nL 62.157901 94.996471 \nL 62.18073 94.739219 \nL 62.272049 94.29395 \nL 62.22639 94.80058 \nL 62.317708 94.357383 \nL 62.454685 95.648839 \nL 62.477515 95.399998 \nL 62.500344 95.152713 \nL 62.546003 95.75498 \nL 62.591662 95.264311 \nL 62.72864 95.959577 \nL 62.751469 95.71879 \nL 62.819958 96.058212 \nL 63.002594 97.791424 \nL 63.025424 97.553718 \nL 63.048254 97.317389 \nL 63.116742 97.630346 \nL 63.139572 97.90195 \nL 63.185231 97.43538 \nL 63.20806 97.705228 \nL 63.299379 97.778429 \nL 63.367867 97.095212 \nL 63.390697 97.360003 \nL 63.436356 96.910603 \nL 63.459186 96.687763 \nL 63.527674 96.99049 \nL 63.710311 98.088452 \nL 63.847288 97.256837 \nL 63.870118 97.506614 \nL 64.098413 99.482916 \nL 64.121243 99.270002 \nL 64.212561 99.319998 \nL 64.28105 98.693684 \nL 64.395197 99.417034 \nL 64.418027 99.211112 \nL 64.440856 99.00621 \nL 64.509345 99.260098 \nL 64.532175 99.487322 \nL 64.577834 99.082134 \nL 64.600663 98.881017 \nL 64.646322 99.331805 \nL 64.714811 99.577891 \nL 64.737641 99.378467 \nL 64.806129 98.785873 \nL 64.851788 99.227546 \nL 64.874618 99.446821 \nL 64.920277 99.056069 \nL 64.943107 98.86206 \nL 64.988766 99.297213 \nL 65.011595 99.513271 \nL 65.057254 99.127618 \nL 65.080084 99.342582 \nL 65.125743 98.960368 \nL 65.171402 99.387121 \nL 65.194232 99.197223 \nL 65.217061 99.409095 \nL 65.26272 99.03176 \nL 65.28555 99.242571 \nL 65.331209 98.868536 \nL 65.376868 99.287109 \nL 65.422527 99.70196 \nL 65.468186 99.330869 \nL 65.536675 99.557441 \nL 65.605164 99.009059 \nL 65.627993 99.213015 \nL 65.673652 98.851304 \nL 65.901948 97.839579 \nL 66.198732 99.654782 \nL 66.29005 98.967844 \nL 66.358539 99.18 \nL 66.381369 99.369898 \nL 66.427028 99.03176 \nL 66.472687 99.052725 \nL 66.609664 98.41042 \nL 66.792301 99.541417 \nL 66.81513 99.377647 \nL 66.883619 98.890175 \nL 66.929278 99.2534 \nL 67.043426 99.470772 \nL 67.111914 99.666653 \nL 67.180403 99.189579 \nL 67.203233 99.366492 \nL 67.248892 99.051379 \nL 67.271721 99.227546 \nL 67.36304 98.934608 \nL 67.31738 99.246314 \nL 67.408699 98.954333 \nL 67.477187 98.820003 \nL 67.545676 99.338082 \nL 67.636994 99.373841 \nL 67.682653 99.069632 \nL 67.728312 99.409095 \nL 67.773972 99.106958 \nL 67.956608 98.549996 \nL 68.047926 98.902981 \nL 68.070756 98.756286 \nL 68.093585 98.610106 \nL 68.139244 98.940422 \nL 68.321881 99.932495 \nL 68.34471 99.787073 \nL 68.413199 99.35379 \nL 68.458858 99.673613 \nL 68.550176 100.306687 \nL 68.618665 100.176878 \nL 68.824131 99.500265 \nL 68.89262 99.670585 \nL 68.915449 99.531629 \nL 68.961108 99.255104 \nL 69.006768 99.562572 \nL 69.029597 99.715555 \nL 69.075256 99.440691 \nL 69.120915 99.167625 \nL 69.166574 99.471876 \nL 69.189404 99.335958 \nL 69.303552 99.517897 \nL 69.349211 99.248984 \nL 69.4177 99.414226 \nL 69.623166 100.179244 \nL 69.645995 100.046501 \nL 69.691654 100.336979 \nL 69.874291 101.20696 \nL 69.89712 101.07488 \nL 69.91995 100.943221 \nL 69.965609 101.22556 \nL 70.125416 102.200148 \nL 70.193904 102.075322 \nL 70.285223 101.821813 \nL 70.308052 101.958456 \nL 70.4222 102.371499 \nL 70.44503 102.242426 \nL 70.513518 102.119997 \nL 70.536348 102.25418 \nL 70.604836 102.654322 \nL 70.650496 102.398762 \nL 70.833132 101.905717 \nL 70.855962 102.037471 \nL 70.901621 101.787778 \nL 71.015768 101.424038 \nL 71.038598 101.554961 \nL 71.152746 101.699995 \nL 71.358212 100.861188 \nL 71.381041 100.990146 \nL 71.518019 101.509939 \nL 71.540848 101.390707 \nL 71.609337 101.035 \nL 71.654996 101.288141 \nL 71.860462 101.927523 \nL 71.997439 101.467493 \nL 72.020269 101.590731 \nL 72.043098 101.713642 \nL 72.088758 101.48235 \nL 72.111587 101.604904 \nL 72.225735 101.504335 \nL 72.271394 101.747099 \nL 72.339883 101.639685 \nL 72.362712 101.525973 \nL 72.408371 101.76675 \nL 72.591008 102.254864 \nL 72.659496 101.917125 \nL 72.705156 102.152812 \nL 72.864962 102.512905 \nL 73.047599 102.07977 \nL 73.161747 102.429138 \nL 73.184576 102.319621 \nL 73.253065 102.43818 \nL 73.344383 102.00392 \nL 73.50419 102.352752 \nL 73.52702 102.24537 \nL 73.572679 102.469134 \nL 73.595508 102.362004 \nL 73.732486 102.592698 \nL 73.800974 102.706767 \nL 73.869463 102.389226 \nL 73.937952 102.717807 \nL 74.00644 102.616365 \nL 74.052099 102.406942 \nL 74.097758 102.624104 \nL 74.303224 103.167491 \nL 74.371713 102.856627 \nL 74.417372 103.069109 \nL 74.463031 103.280593 \nL 74.50869 103.074545 \nL 74.55435 102.869475 \nL 74.622838 102.977751 \nL 74.736986 103.293746 \nL 74.759816 103.192031 \nL 74.919622 102.894446 \nL 75.079429 103.410823 \nL 75.102259 103.310727 \nL 75.170748 103.414524 \nL 75.239236 103.116245 \nL 75.376214 103.32305 \nL 75.444702 103.22676 \nL 75.467532 103.327087 \nL 75.650168 103.728364 \nL 75.695827 103.53324 \nL 75.741486 103.73054 \nL 75.924123 104.122974 \nL 76.152418 103.548181 \nL 76.220907 103.837355 \nL 76.289396 103.743241 \nL 76.517691 103.182348 \nL 76.631839 103.657024 \nL 76.677498 103.470954 \nL 76.882964 102.828837 \nL 76.905794 102.92294 \nL 77.042771 103.299329 \nL 77.065601 103.208318 \nL 77.11126 103.026863 \nL 77.156919 103.212524 \nL 77.339555 103.584161 \nL 77.499362 103.31816 \nL 77.545021 103.500005 \nL 77.59068 103.32183 \nL 77.61351 103.233026 \nL 77.659169 103.414114 \nL 77.796146 103.596988 \nL 77.978783 103.248829 \nL 78.13859 103.518604 \nL 78.298397 103.262246 \nL 78.344056 103.437928 \nL 78.389715 103.26602 \nL 78.503863 103.011785 \nL 78.526692 103.09918 \nL 78.572351 103.273464 \nL 78.61801 103.103543 \nL 78.800647 102.771303 \nL 78.914795 103.032688 \nL 78.937624 102.94911 \nL 79.006113 102.868276 \nL 79.028942 102.953968 \nL 79.14309 103.044001 \nL 79.211579 102.796064 \nL 79.280068 102.883638 \nL 79.302897 102.968341 \nL 79.348556 102.804139 \nL 79.508363 102.39974 \nL 79.531193 102.484106 \nL 79.599681 102.571406 \nL 79.622511 102.490583 \nL 79.64534 102.409928 \nL 79.691 102.577547 \nL 79.713829 102.661114 \nL 79.759488 102.500225 \nL 79.782318 102.583634 \nL 79.827977 102.423334 \nL 79.873636 102.58969 \nL 79.964954 102.758118 \nL 79.987784 102.678326 \nL 80.147591 102.446329 \nL 80.261739 102.695159 \nL 80.284568 102.616365 \nL 80.375886 102.462394 \nL 80.398716 102.543796 \nL 80.512864 102.789735 \nL 80.535693 102.711624 \nL 80.604182 102.636521 \nL 80.627011 102.717039 \nL 80.741159 102.802499 \nL 80.763989 102.725083 \nL 80.809648 102.884826 \nL 80.832477 102.964482 \nL 80.878137 102.810048 \nL 81.083603 102.432692 \nL 81.311898 102.910481 \nL 81.540194 102.463635 \nL 81.563023 102.541451 \nL 81.608682 102.392022 \nL 81.631512 102.469702 \nL 81.72283 102.172369 \nL 81.791319 102.253276 \nL 82.019614 102.720004 \nL 82.042444 102.646341 \nL 82.088103 102.79863 \nL 82.133762 102.950403 \nL 82.202251 102.879117 \nL 82.339228 102.589407 \nL 82.362058 102.664836 \nL 82.476205 102.892575 \nL 82.499035 102.819995 \nL 82.613183 102.752441 \nL 82.636012 102.826987 \nL 82.681671 102.682899 \nL 82.704501 102.757309 \nL 82.727331 102.685454 \nL 82.77299 102.833895 \nL 82.841478 102.910102 \nL 82.864308 102.838468 \nL 83.092603 102.272822 \nL 83.115433 102.346475 \nL 83.206751 102.496219 \nL 83.229581 102.425857 \nL 83.298069 102.35864 \nL 83.320899 102.431682 \nL 83.457876 102.582709 \nL 83.480706 102.512905 \nL 83.526365 102.657686 \nL 83.549195 102.587977 \nL 83.594854 102.732285 \nL 83.640513 102.593213 \nL 83.686172 102.454593 \nL 83.731831 102.598417 \nL 84.028615 103.243099 \nL 84.051445 103.174147 \nL 84.097104 103.315027 \nL 84.119933 103.385304 \nL 84.165593 103.247715 \nL 84.348229 102.977751 \nL 84.530865 103.259817 \nL 84.667843 103.127737 \nL 84.80482 103.268691 \nL 84.82765 103.201526 \nL 84.873309 103.338674 \nL 85.124434 103.816641 \nL 85.192923 103.750496 \nL 85.215752 103.817872 \nL 85.284241 103.885657 \nL 85.30707 103.819091 \nL 85.375559 103.620004 \nL 85.444048 103.687873 \nL 85.489707 103.82151 \nL 85.535366 103.689472 \nL 85.558195 103.62361 \nL 85.603855 103.756836 \nL 85.740832 103.890651 \nL 85.809321 103.694213 \nL 85.85498 103.826252 \nL 86.060446 104.154812 \nL 86.151764 104.025013 \nL 86.174593 104.090107 \nL 86.265912 104.22 \nL 86.288741 104.155285 \nL 86.3344 104.026149 \nL 86.402889 104.091053 \nL 86.494207 104.348574 \nL 86.539866 104.22 \nL 86.562696 104.155853 \nL 86.608355 104.284053 \nL 86.631185 104.22 \nL 86.699673 104.283869 \nL 86.722503 104.22 \nL 86.836651 104.029229 \nL 86.85948 104.092914 \nL 86.88231 104.156504 \nL 86.927969 104.029776 \nL 86.950798 104.093272 \nL 86.973628 104.030049 \nL 87.019287 104.156778 \nL 87.247583 104.533877 \nL 87.270412 104.470923 \nL 87.316071 104.595853 \nL 87.567196 105.028031 \nL 87.612855 104.902759 \nL 87.658515 105.02576 \nL 87.978128 105.631692 \nL 88.183594 105.195934 \nL 88.206424 105.256212 \nL 88.38906 105.735462 \nL 88.434719 105.612314 \nL 88.640185 105.302948 \nL 88.708674 105.360776 \nL 88.731504 105.299998 \nL 88.822822 105.177397 \nL 88.845651 105.236545 \nL 89.005458 105.410282 \nL 89.233754 104.929381 \nL 89.256583 104.987983 \nL 89.370731 105.044297 \nL 89.599027 104.687906 \nL 89.850152 105.207094 \nL 89.872981 105.14842 \nL 90.009959 105.029172 \nL 90.124107 105.199361 \nL 90.146936 105.141149 \nL 90.306743 104.850409 \nL 90.329573 104.907275 \nL 90.420891 105.019741 \nL 90.44372 104.962138 \nL 90.580698 104.84553 \nL 90.603527 104.90196 \nL 90.649186 104.787565 \nL 90.808993 104.615515 \nL 90.877482 104.783938 \nL 90.923141 104.670573 \nL 91.014459 104.557071 \nL 91.037289 104.612997 \nL 91.219925 104.834438 \nL 91.288414 104.66602 \nL 91.334073 104.776819 \nL 91.425391 104.886499 \nL 91.448221 104.830574 \nL 91.47105 104.774717 \nL 91.516709 104.884822 \nL 91.630857 104.937971 \nL 91.653687 104.88233 \nL 91.699346 104.991752 \nL 91.745005 105.1009 \nL 91.813494 105.044297 \nL 91.950471 104.931731 \nL 92.155937 105.200003 \nL 92.247255 105.088967 \nL 92.270085 105.142705 \nL 92.49838 105.460735 \nL 92.566869 105.296923 \nL 92.612528 105.40317 \nL 92.635358 105.456198 \nL 92.681017 105.347328 \nL 92.703846 105.400294 \nL 92.817994 105.343228 \nL 93.000631 105.550716 \nL 93.04629 105.442787 \nL 93.091949 105.547515 \nL 93.206097 105.702353 \nL 93.228926 105.648557 \nL 93.297415 105.698804 \nL 93.365903 105.537994 \nL 93.388733 105.589892 \nL 93.434392 105.48301 \nL 93.54854 105.216904 \nL 93.594199 105.320533 \nL 93.845324 105.677849 \nL 93.868154 105.624957 \nL 93.913813 105.727251 \nL 93.936642 105.674416 \nL 94.07362 105.772819 \nL 94.164938 105.6659 \nL 94.187767 105.716663 \nL 94.393233 105.96552 \nL 94.461722 106.013722 \nL 94.530211 105.857123 \nL 94.644359 105.903401 \nL 94.712847 105.849563 \nL 94.735677 105.899516 \nL 94.758506 105.949412 \nL 94.804165 105.845804 \nL 94.826995 105.794095 \nL 94.872654 105.893723 \nL 94.986802 106.040644 \nL 95.009631 105.989056 \nL 95.192268 105.779727 \nL 95.374904 105.972979 \nL 95.511882 105.867201 \nL 95.740177 106.155733 \nL 95.808666 106.202022 \nL 95.877155 106.050285 \nL 95.945643 106.195366 \nL 96.014132 106.142748 \nL 96.219598 105.789742 \nL 96.242427 105.837897 \nL 96.265257 105.886 \nL 96.310916 105.786262 \nL 96.333746 105.736472 \nL 96.379405 105.832519 \nL 96.493553 105.974252 \nL 96.516382 105.924582 \nL 96.6077 105.823635 \nL 96.63053 105.871322 \nL 96.721848 105.964615 \nL 96.744678 105.915225 \nL 96.927314 105.714917 \nL 96.950144 105.762295 \nL 96.995803 105.664323 \nL 97.13278 105.563633 \nL 97.15561 105.610863 \nL 97.201269 105.513538 \nL 97.224098 105.464951 \nL 97.269757 105.559264 \nL 97.452394 105.743974 \nL 97.498053 105.647185 \nL 97.566542 105.692375 \nL 97.772008 105.921607 \nL 97.931815 105.773976 \nL 97.954644 105.820212 \nL 98.000303 105.72448 \nL 98.023133 105.770664 \nL 98.18294 105.530828 \nL 98.205769 105.576923 \nL 98.251428 105.668965 \nL 98.319917 105.62 \nL 98.342747 105.572617 \nL 98.388406 105.664375 \nL 98.411235 105.617045 \nL 98.571042 105.84388 \nL 98.593872 105.796655 \nL 98.66236 105.747874 \nL 98.68519 105.793349 \nL 98.708019 105.838775 \nL 98.753679 105.744673 \nL 98.776508 105.697695 \nL 98.822167 105.788412 \nL 98.981974 105.920571 \nL 99.141781 105.777009 \nL 99.324417 106.044198 \nL 99.347247 105.997672 \nL 99.370077 105.951199 \nL 99.415736 106.040434 \nL 99.438565 106.084983 \nL 99.484224 105.992178 \nL 99.644031 105.849978 \nL 99.826668 106.023679 \nL 99.986475 105.792591 \nL 100.009304 105.836699 \nL 100.054963 105.924782 \nL 100.100622 105.833413 \nL 100.21477 105.695214 \nL 100.2376 105.739148 \nL 100.420236 105.911019 \nL 100.443066 105.865687 \nL 100.488725 105.952897 \nL 100.511554 105.907612 \nL 100.557214 105.994649 \nL 100.602873 105.904221 \nL 100.671361 105.857433 \nL 100.694191 105.900841 \nL 100.808339 106.117251 \nL 100.853998 106.027196 \nL 100.922486 105.980481 \nL 100.945316 106.02359 \nL 101.105123 106.148825 \nL 101.173612 106.189726 \nL 101.287759 105.966534 \nL 101.379078 106.137391 \nL 101.447566 106.091039 \nL 101.561714 105.869409 \nL 101.607373 105.954511 \nL 101.698691 106.037663 \nL 101.721521 105.993519 \nL 101.79001 105.947719 \nL 101.812839 105.990044 \nL 101.949816 106.070951 \nL 102.086794 105.89387 \nL 102.109623 105.935953 \nL 102.132453 105.977995 \nL 102.178112 105.890616 \nL 102.200942 105.93262 \nL 102.315089 105.80034 \nL 102.337919 105.842266 \nL 102.452067 105.966114 \nL 102.474896 105.9227 \nL 102.520555 105.83601 \nL 102.566214 105.91942 \nL 102.79451 106.249531 \nL 102.81734 106.206296 \nL 102.840169 106.163103 \nL 102.885828 106.245646 \nL 102.908658 106.202495 \nL 103.228272 106.608314 \nL 103.273931 106.522323 \nL 103.342419 106.560853 \nL 103.479397 106.720943 \nL 103.502226 106.678102 \nL 103.639204 106.588064 \nL 103.776181 106.664245 \nL 103.79901 106.621688 \nL 103.84467 106.702175 \nL 103.867499 106.65966 \nL 104.027306 106.85776 \nL 104.050136 106.815329 \nL 104.095795 106.730595 \nL 104.141454 106.810487 \nL 104.232772 106.887751 \nL 104.255602 106.845489 \nL 104.415408 106.714298 \nL 104.529556 106.749326 \nL 104.552386 106.707379 \nL 104.598045 106.786557 \nL 104.803511 106.978784 \nL 104.917659 106.93198 \nL 105.077466 107.044335 \nL 105.397079 106.625452 \nL 105.511227 106.819998 \nL 105.579716 106.776521 \nL 105.693864 106.571467 \nL 105.739523 106.648983 \nL 105.808011 106.685462 \nL 105.830841 106.644604 \nL 106.059136 106.39631 \nL 106.127625 106.432905 \nL 106.150455 106.392414 \nL 106.287432 106.307806 \nL 106.40158 106.342461 \nL 106.515728 106.298522 \nL 106.652705 106.371217 \nL 106.744023 106.289322 \nL 106.766853 106.327436 \nL 106.812512 106.403554 \nL 106.881 106.361723 \nL 107.086466 106.159313 \nL 107.109296 106.197233 \nL 107.154955 106.118024 \nL 107.177785 106.078474 \nL 107.223444 106.154208 \nL 107.314762 106.228055 \nL 107.337592 106.18858 \nL 107.360421 106.149135 \nL 107.40608 106.224544 \nL 107.565887 106.410588 \nL 107.588717 106.371217 \nL 107.794183 106.094966 \nL 107.817012 106.132402 \nL 107.839842 106.169806 \nL 107.885501 106.091717 \nL 108.090967 105.894201 \nL 108.159456 105.930039 \nL 108.182285 105.89132 \nL 108.250774 105.851224 \nL 108.273603 105.888445 \nL 108.479069 106.070878 \nL 108.501899 106.032327 \nL 108.547558 106.106227 \nL 108.684535 106.176656 \nL 109.049808 105.714917 \nL 109.255274 105.895389 \nL 109.415081 105.779091 \nL 109.643377 105.99435 \nL 109.689036 105.918994 \nL 109.734695 105.991379 \nL 109.803184 106.099734 \nL 109.848843 106.02451 \nL 109.96299 105.910498 \nL 109.98582 105.946531 \nL 110.122797 106.015515 \nL 110.145627 105.978142 \nL 110.191286 106.049875 \nL 110.259775 106.157258 \nL 110.305434 106.082606 \nL 110.442411 106.005132 \nL 110.579388 106.073401 \nL 110.739195 105.959358 \nL 110.944661 106.133469 \nL 110.99032 106.059754 \nL 111.03598 106.130341 \nL 111.127298 106.127224 \nL 111.424082 105.794999 \nL 111.5154 105.79245 \nL 111.53823 105.756086 \nL 111.583889 105.826232 \nL 111.698037 105.858611 \nL 111.903503 105.67521 \nL 111.926332 105.710107 \nL 111.971991 105.638006 \nL 112.086139 105.529025 \nL 112.108969 105.563864 \nL 112.268776 105.6659 \nL 112.382923 105.627823 \nL 112.405753 105.662441 \nL 112.451412 105.590986 \nL 112.588389 105.517575 \nL 112.611219 105.552115 \nL 112.656878 105.481001 \nL 112.748196 105.409058 \nL 112.771026 105.443544 \nL 112.930833 105.544744 \nL 113.136299 105.366359 \nL 113.159128 105.40063 \nL 113.204787 105.330306 \nL 113.387424 105.188468 \nL 113.501572 105.221094 \nL 113.638549 105.080992 \nL 113.661378 105.115084 \nL 113.707038 105.183185 \nL 113.752697 105.113686 \nL 113.821185 105.078311 \nL 113.844015 105.112298 \nL 113.980992 105.178695 \nL 114.232117 104.935963 \nL 114.346265 104.96861 \nL 114.460413 104.933208 \nL 114.551731 105.067749 \nL 114.59739 104.999333 \nL 114.780027 104.861822 \nL 114.917004 104.995164 \nL 114.939834 104.961176 \nL 115.076811 104.892255 \nL 115.236618 104.991037 \nL 115.327936 104.92292 \nL 115.350766 104.956114 \nL 115.442084 105.021817 \nL 115.464913 104.988119 \nL 115.487743 104.954442 \nL 115.533402 105.020603 \nL 115.62472 105.019394 \nL 115.738868 104.918152 \nL 115.761698 104.951125 \nL 115.898675 105.015787 \nL 115.921504 104.982347 \nL 115.967164 105.048014 \nL 116.218289 105.275495 \nL 116.241118 105.242133 \nL 116.286777 105.307264 \nL 116.332436 105.372294 \nL 116.378096 105.305639 \nL 116.492243 105.205107 \nL 116.515073 105.237565 \nL 116.67488 105.333139 \nL 116.766198 105.200728 \nL 116.811857 105.265333 \nL 116.926005 105.296008 \nL 117.085812 105.195665 \nL 117.19996 105.22633 \nL 117.291278 105.160022 \nL 117.314107 105.19208 \nL 117.451085 105.254603 \nL 117.565232 105.220437 \nL 117.588062 105.252332 \nL 117.610892 105.284206 \nL 117.656551 105.218976 \nL 117.725039 105.185693 \nL 117.770698 105.24932 \nL 117.953335 105.374618 \nL 118.090312 105.3081 \nL 118.113142 105.339695 \nL 118.318608 105.49549 \nL 118.478415 105.460462 \nL 118.661051 105.583752 \nL 118.72954 105.487242 \nL 118.798028 105.580819 \nL 118.843688 105.643089 \nL 118.889347 105.578868 \nL 118.980665 105.576923 \nL 119.003494 105.607982 \nL 119.071983 105.701028 \nL 119.117642 105.636996 \nL 119.345938 105.506446 \nL 119.437256 105.504616 \nL 119.619893 105.438492 \nL 119.779699 105.528973 \nL 120.122143 105.243058 \nL 120.190631 105.272951 \nL 120.236291 105.210317 \nL 120.396097 105.177018 \nL 120.533075 105.17501 \nL 120.692882 105.141953 \nL 121.080984 105.594781 \nL 121.103814 105.56377 \nL 121.28645 105.499144 \nL 121.537575 105.646007 \nL 121.674553 105.643068 \nL 121.81153 105.640145 \nL 121.948507 105.576923 \nL 121.971337 105.606605 \nL 122.085485 105.574147 \nL 122.268121 105.510441 \nL 122.450757 105.566793 \nL 122.587735 105.564059 \nL 122.793201 105.649303 \nL 122.907349 105.617166 \nL 122.930178 105.646417 \nL 122.975837 105.70485 \nL 123.044326 105.614349 \nL 123.204133 105.463085 \nL 123.249792 105.521408 \nL 123.34111 105.519668 \nL 123.36394 105.489702 \nL 123.592235 105.367747 \nL 123.729213 105.424198 \nL 123.752042 105.394432 \nL 123.911849 105.362411 \nL 124.003167 105.360897 \nL 124.025997 105.331273 \nL 124.254292 105.211011 \nL 124.551077 105.40993 \nL 124.665224 105.379003 \nL 124.688054 105.407586 \nL 124.733713 105.464699 \nL 124.802202 105.376721 \nL 124.984838 105.200639 \nL 125.030497 105.257647 \nL 125.121815 105.313867 \nL 125.167475 105.255618 \nL 125.304452 105.253594 \nL 125.441429 105.25158 \nL 125.555577 105.221299 \nL 125.578407 105.249572 \nL 125.852361 105.416512 \nL 125.875191 105.387645 \nL 125.943679 105.47187 \nL 126.012168 105.555931 \nL 126.080657 105.469451 \nL 126.149145 105.43988 \nL 126.194805 105.495795 \nL 126.377441 105.662194 \nL 126.4231 105.604749 \nL 126.605737 105.544833 \nL 126.651396 105.600328 \nL 126.719884 105.514573 \nL 126.788373 105.485223 \nL 126.834032 105.540612 \nL 126.94818 105.566566 \nL 126.971009 105.538094 \nL 127.085157 105.508002 \nL 127.107987 105.535581 \nL 127.244964 105.644835 \nL 127.290623 105.588089 \nL 127.496089 105.445001 \nL 127.518919 105.472448 \nL 127.655896 105.636754 \nL 127.724385 105.552157 \nL 127.838533 105.522354 \nL 127.861362 105.549649 \nL 127.998339 105.547147 \nL 128.226635 105.322499 \nL 128.272294 105.3769 \nL 128.614737 105.61826 \nL 128.774544 105.533152 \nL 128.797374 105.560095 \nL 128.911522 105.585324 \nL 128.934351 105.557603 \nL 129.162647 105.390195 \nL 129.185476 105.417038 \nL 129.413772 105.576087 \nL 129.436601 105.548561 \nL 129.550749 105.57359 \nL 129.710556 105.597704 \nL 129.893193 105.540439 \nL 129.984511 105.592658 \nL 130.03017 105.538025 \nL 130.212806 105.427484 \nL 130.235636 105.453943 \nL 130.395443 105.531622 \nL 130.418272 105.504464 \nL 130.55525 105.395289 \nL 130.600909 105.447966 \nL 130.715057 105.472763 \nL 130.737886 105.445742 \nL 130.897693 105.416565 \nL 130.989011 105.468237 \nL 131.03467 105.414404 \nL 131.148818 105.333103 \nL 131.194477 105.385406 \nL 131.491261 105.565557 \nL 131.696727 105.430381 \nL 131.719557 105.456324 \nL 131.765216 105.508165 \nL 131.833705 105.42822 \nL 131.925023 105.426779 \nL 131.947853 105.45265 \nL 132.153319 105.58014 \nL 132.176148 105.553592 \nL 132.335955 105.524735 \nL 132.495762 105.548077 \nL 132.792546 105.30953 \nL 132.815376 105.335142 \nL 132.929523 105.411192 \nL 132.975183 105.358731 \nL 133.203478 105.252185 \nL 133.454603 105.377478 \nL 133.660069 105.297486 \nL 133.819876 105.372105 \nL 133.842706 105.346177 \nL 134.093831 105.215022 \nL 134.253638 105.2894 \nL 134.276467 105.263635 \nL 134.459104 105.159649 \nL 134.481933 105.184767 \nL 134.687399 105.258241 \nL 134.870036 105.154802 \nL 134.892865 105.179794 \nL 135.098331 105.303289 \nL 135.121161 105.277798 \nL 135.303797 105.225126 \nL 135.440775 105.323755 \nL 135.486434 105.272982 \nL 135.714729 105.17 \nL 135.806047 105.168922 \nL 135.828877 105.143693 \nL 136.034343 105.06664 \nL 136.262639 105.213245 \nL 136.285468 105.188137 \nL 136.445275 105.161463 \nL 136.742059 105.330831 \nL 136.879037 105.27968 \nL 136.901866 105.30402 \nL 137.016014 105.277908 \nL 137.244309 105.176829 \nL 137.289969 105.225337 \nL 137.358457 105.151001 \nL 137.541094 105.100044 \nL 137.655241 105.123238 \nL 137.678071 105.098582 \nL 137.792219 105.072996 \nL 137.815048 105.097126 \nL 138.089003 105.239936 \nL 138.134662 105.190829 \nL 138.203151 105.262783 \nL 138.340128 105.261064 \nL 138.499935 105.234905 \nL 138.819549 105.423604 \nL 138.956526 105.421633 \nL 139.161992 105.538567 \nL 139.184822 105.514237 \nL 139.207651 105.489928 \nL 139.27614 105.560715 \nL 139.458776 105.60559 \nL 139.572924 105.532143 \nL 139.618583 105.579126 \nL 139.869708 105.693962 \nL 140.120834 105.571088 \nL 140.257811 105.663576 \nL 140.30347 105.615495 \nL 140.508936 105.494155 \nL 140.531766 105.517407 \nL 140.80572 105.654339 \nL 141.011186 105.580529 \nL 141.262311 105.740288 \nL 141.285141 105.7165 \nL 141.3308 105.668965 \nL 141.399289 105.73787 \nL 141.490607 105.782918 \nL 141.536266 105.735462 \nL 141.581925 105.688059 \nL 141.650414 105.756748 \nL 141.901539 105.868384 \nL 142.107005 105.794999 \nL 142.403789 105.95122 \nL 142.426619 105.927694 \nL 142.495107 105.995527 \nL 142.86038 106.263688 \nL 142.88321 106.240199 \nL 142.928869 106.193258 \nL 142.997358 106.260497 \nL 143.157164 106.325449 \nL 143.179994 106.302023 \nL 143.545267 106.065568 \nL 143.682244 106.062713 \nL 143.796392 106.083058 \nL 143.88771 106.03575 \nL 144.024688 106.032947 \nL 144.184494 106.052315 \nL 144.344301 106.02645 \nL 144.572597 106.111931 \nL 144.709574 106.109034 \nL 144.892211 106.150076 \nL 145.097677 106.07849 \nL 145.303143 106.141276 \nL 145.485779 106.0928 \nL 145.736904 106.198773 \nL 145.896711 106.173097 \nL 146.056518 106.191818 \nL 146.239154 106.143642 \nL 146.421791 106.183922 \nL 146.513109 106.226047 \nL 146.604427 106.18 \nL 146.809893 106.109686 \nL 146.9697 106.128333 \nL 147.106678 106.125489 \nL 147.334973 106.208157 \nL 147.449121 106.227519 \nL 147.631757 106.267111 \nL 147.791564 106.241839 \nL 148.01986 106.323614 \nL 148.179667 106.298348 \nL 148.453621 106.42176 \nL 148.613428 106.396446 \nL 148.796065 106.435218 \nL 148.955872 106.409973 \nL 149.184167 106.490323 \nL 149.412463 106.399359 \nL 149.54944 106.396199 \nL 149.800565 106.284028 \nL 149.937542 106.281047 \nL 150.05169 106.299789 \nL 150.257156 106.358821 \nL 150.394134 106.355746 \nL 150.57677 106.39387 \nL 150.759406 106.347587 \nL 150.873554 106.324008 \nL 151.033361 106.299494 \nL 151.193168 106.317006 \nL 151.467123 106.185578 \nL 151.6041 106.182786 \nL 151.695418 106.222651 \nL 151.900884 106.280847 \nL 152.060691 106.256665 \nL 152.266157 106.314567 \nL 152.540112 106.184595 \nL 152.63143 106.141434 \nL 152.791237 106.117661 \nL 152.951044 106.135151 \nL 153.065192 106.153488 \nL 153.247828 106.19095 \nL 153.544612 106.041722 \nL 153.704419 106.059202 \nL 153.841396 106.056652 \nL 154.046862 106.113928 \nL 154.18384 106.111305 \nL 154.457794 106.227771 \nL 154.754579 106.080246 \nL 154.891556 106.077691 \nL 155.165511 105.951783 \nL 155.348147 105.988824 \nL 155.462295 106.006888 \nL 155.644931 106.043719 \nL 155.918886 105.918847 \nL 156.033034 105.896956 \nL 156.2385 105.833781 \nL 156.443966 105.890153 \nL 156.626602 105.847455 \nL 156.969046 106.019999 \nL 157.174512 105.957155 \nL 157.402807 106.032059 \nL 157.516955 106.049712 \nL 157.631103 106.028022 \nL 157.836569 105.965562 \nL 157.973546 105.963238 \nL 158.110523 105.96092 \nL 158.224671 105.939449 \nL 158.384478 105.91728 \nL 158.589944 105.972317 \nL 158.77258 105.930355 \nL 158.978046 105.985165 \nL 159.183512 105.923599 \nL 159.343319 105.940317 \nL 159.571615 105.859404 \nL 159.731422 105.876159 \nL 159.868399 105.873993 \nL 160.188013 106.022349 \nL 160.302161 106.039545 \nL 160.530456 106.112046 \nL 160.690263 106.090098 \nL 160.85007 106.106326 \nL 161.078366 106.026208 \nL 161.192513 106.005274 \nL 161.35232 105.98362 \nL 161.489298 105.981349 \nL 161.671934 105.940517 \nL 161.923059 106.030776 \nL 162.128525 105.970824 \nL 162.265503 105.968584 \nL 162.470969 105.908937 \nL 162.607946 105.906782 \nL 162.699264 105.942803 \nL 162.836241 105.940611 \nL 162.950389 105.957471 \nL 163.133026 105.991831 \nL 163.338492 105.93262 \nL 163.543958 105.985113 \nL 163.840742 105.850588 \nL 163.93206 105.81219 \nL 164.069037 105.810187 \nL 164.183185 105.790052 \nL 164.502799 105.638126 \nL 164.639776 105.63635 \nL 164.776754 105.634578 \nL 165.073538 105.759009 \nL 165.279004 105.701275 \nL 165.438811 105.717394 \nL 165.598618 105.696991 \nL 165.781254 105.730962 \nL 165.872572 105.76609 \nL 166.078038 105.817694 \nL 166.283504 105.760376 \nL 166.5118 105.829554 \nL 166.625948 105.845972 \nL 166.740095 105.826263 \nL 166.991221 105.732618 \nL 167.242346 105.819061 \nL 167.470641 105.744089 \nL 167.607619 105.742233 \nL 167.813085 105.68583 \nL 167.972891 105.701601 \nL 168.087039 105.71794 \nL 168.269676 105.751129 \nL 168.383823 105.767368 \nL 168.56646 105.800393 \nL 168.657778 105.834606 \nL 168.817585 105.850052 \nL 168.931733 105.866118 \nL 169.182858 105.9508 \nL 169.342665 105.966008 \nL 169.456813 105.946646 \nL 169.639449 105.943892 \nL 169.867745 106.010684 \nL 170.073211 105.98996 \nL 170.347165 106.090644 \nL 170.484143 106.123344 \nL 170.643949 106.138148 \nL 170.940734 106.046269 \nL 171.054881 106.027091 \nL 171.306007 105.971171 \nL 171.420154 105.95213 \nL 171.62562 105.931785 \nL 171.853916 105.962949 \nL 172.105041 105.907544 \nL 172.333337 105.938629 \nL 172.561632 105.900978 \nL 172.858416 105.98229 \nL 173.269348 105.805655 \nL 173.497644 105.83663 \nL 173.611792 105.886074 \nL 173.817258 105.900163 \nL 174.068383 105.845804 \nL 174.251019 105.843312 \nL 174.524974 105.772104 \nL 174.776099 105.81935 \nL 174.958735 105.816911 \nL 175.095713 105.781509 \nL 175.278349 105.779133 \nL 175.552304 105.842492 \nL 175.780599 105.806029 \nL 175.986065 105.820002 \nL 176.328509 105.699141 \nL 176.602463 105.762132 \nL 177.036225 105.574888 \nL 177.196032 105.556615 \nL 177.333009 105.588079 \nL 177.492816 105.569831 \nL 177.721112 105.534456 \nL 178.040725 105.629363 \nL 178.246191 105.610653 \nL 178.474487 105.640739 \nL 178.725612 105.588957 \nL 179.022396 105.666967 \nL 179.159374 105.697847 \nL 179.410499 105.743485 \nL 179.684454 105.675447 \nL 179.821431 105.641538 \nL 180.026897 105.62307 \nL 180.36934 105.731814 \nL 180.757443 105.582843 \nL 180.962909 105.596627 \nL 181.305352 105.481138 \nL 181.487988 105.479319 \nL 181.693454 105.461356 \nL 181.876091 105.459568 \nL 182.081557 105.441694 \nL 182.332682 105.486784 \nL 182.44683 105.53311 \nL 182.652296 105.546789 \nL 182.903421 105.496888 \nL 183.108887 105.510578 \nL 183.405671 105.429082 \nL 183.656796 105.473731 \nL 183.885092 105.440222 \nL 184.181876 105.515451 \nL 184.364512 105.513622 \nL 184.50149 105.481112 \nL 184.912422 105.321915 \nL 185.117888 105.335673 \nL 185.346183 105.302779 \nL 185.642968 105.377478 \nL 185.825604 105.375864 \nL 186.122388 105.450126 \nL 186.350684 105.417285 \nL 186.53332 105.415618 \nL 186.784445 105.367442 \nL 186.989911 105.380927 \nL 187.195377 105.363873 \nL 187.469332 105.422379 \nL 187.629139 105.436132 \nL 187.788946 105.419482 \nL 188.017241 105.387109 \nL 188.199878 105.385506 \nL 188.382514 105.383907 \nL 188.61081 105.412096 \nL 188.861935 105.364672 \nL 188.976083 105.318551 \nL 189.318526 105.210675 \nL 189.683799 105.32774 \nL 189.957754 105.265732 \nL 190.186049 105.29379 \nL 190.345856 105.307416 \nL 190.551322 105.320643 \nL 190.848106 105.244026 \nL 191.030743 105.242654 \nL 191.16772 105.271231 \nL 191.373186 105.284432 \nL 191.715629 105.178538 \nL 191.898266 105.177255 \nL 192.012414 105.2206 \nL 192.19505 105.219265 \nL 192.514664 105.128973 \nL 192.765789 105.17122 \nL 192.925596 105.184731 \nL 193.336528 105.327598 \nL 193.656142 105.237807 \nL 193.975755 105.322499 \nL 194.135562 105.335721 \nL 194.318199 105.334259 \nL 194.592153 105.274296 \nL 194.797619 105.287166 \nL 195.025915 105.256632 \nL 195.368358 105.354636 \nL 195.573824 105.338633 \nL 195.870608 105.407833 \nL 196.144563 105.34839 \nL 196.30437 105.332845 \nL 196.646813 105.23052 \nL 196.897938 105.271352 \nL 197.217552 105.183937 \nL 197.559996 105.280605 \nL 197.742632 105.279249 \nL 197.925268 105.277892 \nL 198.153564 105.248037 \nL 198.450348 105.316175 \nL 198.701473 105.272172 \nL 198.975428 105.326174 \nL 199.249383 105.268172 \nL 199.546167 105.335747 \nL 199.728803 105.334338 \nL 199.88861 105.319197 \nL 200.094076 105.303742 \nL 200.368031 105.35717 \nL 200.527838 105.369771 \nL 200.733304 105.381983 \nL 200.984429 105.338554 \nL 201.189895 105.350772 \nL 201.577997 105.223991 \nL 201.737804 105.20916 \nL 201.920441 105.20793 \nL 202.034589 105.166026 \nL 202.171566 105.192543 \nL 202.46835 105.258935 \nL 202.650987 105.257647 \nL 202.924941 105.310234 \nL 203.039089 105.350246 \nL 203.198896 105.335421 \nL 203.381532 105.334049 \nL 203.632657 105.372852 \nL 203.860953 105.344001 \nL 203.99793 105.315907 \nL 204.317544 105.232549 \nL 204.659987 105.324523 \nL 204.842624 105.323172 \nL 205.002431 105.308557 \nL 205.322045 105.225778 \nL 205.824295 105.409541 \nL 206.098249 105.354021 \nL 206.303715 105.365802 \nL 206.57767 105.310528 \nL 206.988602 105.440211 \nL 207.125579 105.465614 \nL 207.376705 105.503244 \nL 207.605 105.474903 \nL 207.719148 105.434365 \nL 207.924614 105.419551 \nL 208.038762 105.379139 \nL 208.289887 105.337787 \nL 208.65516 105.44008 \nL 208.883455 105.41207 \nL 209.020433 105.384833 \nL 209.15741 105.409946 \nL 209.362876 105.421422 \nL 209.522683 105.433225 \nL 209.979274 105.585729 \nL 210.16191 105.58412 \nL 210.367376 105.595286 \nL 210.641331 105.541059 \nL 210.823967 105.539508 \nL 211.143581 105.459342 \nL 211.417536 105.508722 \nL 211.645831 105.481101 \nL 211.896957 105.517628 \nL 212.125252 105.49008 \nL 212.536184 105.614722 \nL 212.76448 105.587143 \nL 212.901457 105.560426 \nL 213.129753 105.558486 \nL 213.335219 105.569479 \nL 213.609173 105.541727 \nL 213.837469 105.56521 \nL 214.179912 105.498997 \nL 214.408208 105.497162 \nL 214.773481 105.418541 \nL 214.956117 105.391967 \nL 215.230072 105.364803 \nL 215.595345 105.437504 \nL 215.84647 105.423068 \nL 216.029106 105.396667 \nL 216.280231 105.382336 \nL 216.577015 105.417621 \nL 216.8738 105.378067 \nL 217.193413 105.425497 \nL 217.581516 105.335826 \nL 217.741323 105.297575 \nL 217.992448 105.283544 \nL 218.152255 105.24544 \nL 218.357721 105.256485 \nL 218.608846 105.267215 \nL 218.90563 105.228423 \nL 219.179585 105.251291 \nL 219.499199 105.200271 \nL 219.795983 105.235199 \nL 220.161256 105.159728 \nL 220.503699 105.218676 \nL 220.731995 105.217299 \nL 220.96029 105.215926 \nL 221.234245 105.19003 \nL 221.599518 105.260496 \nL 221.827813 105.259066 \nL 222.261575 105.364829 \nL 222.421382 105.399852 \nL 222.672507 105.410104 \nL 223.060609 105.323398 \nL 223.311734 105.333728 \nL 223.54003 105.332219 \nL 223.722666 105.307117 \nL 223.996621 105.281499 \nL 224.316235 105.327115 \nL 224.613019 105.289521 \nL 224.749996 105.241161 \nL 225.06961 105.191833 \nL 225.343565 105.213934 \nL 225.61752 105.18871 \nL 225.845815 105.187417 \nL 226.188258 105.126608 \nL 226.348065 105.09047 \nL 226.59919 105.077454 \nL 226.850316 105.087926 \nL 227.215588 105.015861 \nL 227.535202 105.061114 \nL 227.67218 105.107135 \nL 227.968964 105.140571 \nL 228.265748 105.104091 \nL 228.539703 105.125924 \nL 228.813657 105.101305 \nL 229.019123 105.088683 \nL 229.247419 105.087542 \nL 229.612692 105.154981 \nL 229.795328 105.177066 \nL 230.023624 105.175815 \nL 230.251919 105.174569 \nL 230.594363 105.2301 \nL 230.799829 105.240383 \nL 230.982465 105.216415 \nL 231.347738 105.145775 \nL 231.553204 105.133279 \nL 231.827159 105.109065 \nL 232.055454 105.107919 \nL 232.329409 105.083815 \nL 232.603364 105.10518 \nL 232.968636 105.035407 \nL 233.265421 105.06797 \nL 233.744841 104.941657 \nL 233.995966 104.951903 \nL 234.269921 104.928298 \nL 234.475387 104.916254 \nL 234.726512 104.904068 \nL 234.909149 104.880968 \nL 235.160274 104.868856 \nL 235.36574 104.856943 \nL 235.571206 104.867379 \nL 235.822331 104.877625 \nL 236.096286 104.854373 \nL 236.324581 104.853573 \nL 236.621365 104.819244 \nL 237.009468 104.895478 \nL 237.39757 104.816695 \nL 237.648695 104.826904 \nL 237.876991 104.826147 \nL 238.128116 104.83632 \nL 238.539048 104.74709 \nL 238.698855 104.713718 \nL 238.92715 104.713103 \nL 239.406571 104.832046 \nL 239.749015 104.776362 \nL 240.00014 104.786503 \nL 240.319753 104.742022 \nL 240.50239 104.71978 \nL 240.822004 104.675536 \nL 241.073129 104.68575 \nL 241.255765 104.706936 \nL 241.52972 104.727828 \nL 241.849334 104.683816 \nL 242.077629 104.683248 \nL 242.328754 104.671866 \nL 242.55705 104.671314 \nL 242.899493 104.616861 \nL 243.264766 104.680325 \nL 243.493062 104.679762 \nL 243.767016 104.700449 \nL 244.08663 104.657004 \nL 244.383414 104.688242 \nL 244.61171 104.68768 \nL 244.885665 104.70823 \nL 245.250937 104.643735 \nL 245.593381 104.695844 \nL 245.981483 104.621003 \nL 246.460904 104.735788 \nL 246.849006 104.66121 \nL 247.008813 104.629352 \nL 247.328427 104.586758 \nL 247.533893 104.575897 \nL 247.6937 104.606977 \nL 247.967655 104.627317 \nL 248.241609 104.605884 \nL 248.469905 104.605426 \nL 248.606882 104.64679 \nL 248.903666 104.677318 \nL 249.109132 104.687217 \nL 249.405917 104.717603 \nL 249.634212 104.71702 \nL 249.862508 104.716436 \nL 250.182121 104.674321 \nL 250.410417 104.67379 \nL 250.638713 104.673259 \nL 250.867008 104.672728 \nL 251.140963 104.651547 \nL 251.392088 104.661257 \nL 251.574724 104.68135 \nL 251.871509 104.711363 \nL 252.191122 104.66969 \nL 252.510736 104.709775 \nL 252.670543 104.739962 \nL 252.967327 104.769722 \nL 253.172793 104.779322 \nL 253.35543 104.758488 \nL 253.560896 104.768077 \nL 253.789191 104.767446 \nL 254.040316 104.776882 \nL 254.314271 104.796339 \nL 254.725203 104.73461 \nL 255.021987 104.74392 \nL 255.364431 104.712851 \nL 255.615556 104.702189 \nL 256.003658 104.651127 \nL 256.209124 104.620635 \nL 256.41459 104.650243 \nL 256.711374 104.659601 \nL 256.93967 104.679063 \nL 257.236454 104.688352 \nL 257.556068 104.667718 \nL 258.058318 104.765853 \nL 258.309443 104.77509 \nL 258.560568 104.764507 \nL 258.948671 104.71406 \nL 259.199796 104.703588 \nL 259.49658 104.693026 \nL 259.861853 104.731534 \nL 260.02166 104.780279 \nL 260.341274 104.799036 \nL 260.729376 104.748967 \nL 261.140308 104.806564 \nL 261.596899 104.727234 \nL 261.893684 104.736245 \nL 262.144809 104.745345 \nL 262.57857 104.812205 \nL 262.898184 104.791907 \nL 263.194968 104.800771 \nL 263.514582 104.780552 \nL 264.085321 104.904321 \nL 264.541912 104.825889 \nL 264.793037 104.815554 \nL 265.089821 104.805124 \nL 265.477924 104.851918 \nL 265.706219 104.87036 \nL 266.094322 104.916896 \nL 266.436765 104.887172 \nL 266.665061 104.86741 \nL 266.893356 104.885731 \nL 267.2358 104.913142 \nL 267.601072 104.874034 \nL 267.989175 104.92015 \nL 268.194641 104.947834 \nL 268.605573 105.003034 \nL 268.970846 104.964026 \nL 269.29046 104.981721 \nL 269.495926 105.009179 \nL 269.861198 105.045348 \nL 270.112324 105.053754 \nL 270.546085 105.117518 \nL 270.979847 105.0504 \nL 271.367949 105.09548 \nL 271.664733 105.084982 \nL 271.938688 105.083888 \nL 272.144154 105.11091 \nL 272.37245 105.091432 \nL 272.646404 105.090334 \nL 272.943188 105.098393 \nL 273.171484 105.115946 \nL 273.673734 105.206043 \nL 273.947689 105.204808 \nL 274.312962 105.23992 \nL 274.792382 105.155175 \nL 275.203314 105.20834 \nL 275.500099 105.197868 \nL 275.842542 105.223723 \nL 276.093667 105.231698 \nL 276.43611 105.257431 \nL 276.710065 105.256149 \nL 277.052508 105.281777 \nL 277.440611 105.234626 \nL 277.783054 105.260202 \nL 278.125498 105.231509 \nL 278.467941 105.257011 \nL 279.061509 105.128353 \nL 279.335464 105.127239 \nL 279.54093 105.153335 \nL 279.860544 105.169927 \nL 280.111669 105.177817 \nL 280.317135 105.150118 \nL 280.659578 105.121913 \nL 280.865044 105.094329 \nL 281.344465 105.012349 \nL 281.61842 105.011393 \nL 281.938033 104.992514 \nL 282.166329 104.973999 \nL 282.691409 104.874907 \nL 283.12517 104.935495 \nL 283.467614 104.907959 \nL 283.467614 104.907959 \n\" clip-path=\"url(#p74268483fb)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#p74268483fb)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p74268483fb\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40585d",
      "metadata": {
        "origin_pos": 29,
        "id": "ec40585d"
      },
      "source": [
        "Each solid curve corresponds to one of the two values of the coin\n",
        "and gives our estimated probability that the coin turns up that value\n",
        "after each group of experiments.\n",
        "The dashed black line gives the true underlying probability.\n",
        "As we get more data by conducting more experiments,\n",
        "the curves converge towards the true probability.\n",
        "You might already begin to see the shape\n",
        "of some of the more advanced questions\n",
        "that preoccupy statisticians:\n",
        "How quickly does this convergence happen?\n",
        "If we had already tested many coins\n",
        "manufactured at the same plant,\n",
        "how might we incorporate this information?\n",
        "\n",
        "##  A More Formal Treatment\n",
        "\n",
        "We have already gotten pretty far: posing\n",
        "a probabilistic model,\n",
        "generating synthetic data,\n",
        "running a statistical estimator,\n",
        "empirically assessing convergence,\n",
        "and reporting error metrics (checking the deviation).\n",
        "However, to go much further,\n",
        "we will need to be more precise.\n",
        "\n",
        "\n",
        "When dealing with randomness,\n",
        "we denote the set of possible outcomes $\\mathcal{S}$\n",
        "and call it the *sample space* or *outcome space*.\n",
        "Here, each element is a distinct possible *outcome*.\n",
        "In the case of rolling a single coin,\n",
        "$\\mathcal{S} = \\{\\textrm{heads}, \\textrm{tails}\\}$.\n",
        "For a single die, $\\mathcal{S} = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "When flipping two coins, possible outcomes are\n",
        "$\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails}), (\\textrm{tails}, \\textrm{heads}),  (\\textrm{tails}, \\textrm{tails})\\}$.\n",
        "*Events* are subsets of the sample space.\n",
        "For instance, the event \"the first coin toss comes up heads\"\n",
        "corresponds to the set $\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails})\\}$.\n",
        "Whenever the outcome $z$ of a random experiment satisfies\n",
        "$z \\in \\mathcal{A}$, then event $\\mathcal{A}$ has occurred.\n",
        "For a single roll of a die, we could define the events\n",
        "\"seeing a $5$\" ($\\mathcal{A} = \\{5\\}$)\n",
        "and \"seeing an odd number\"  ($\\mathcal{B} = \\{1, 3, 5\\}$).\n",
        "In this case, if the die came up $5$,\n",
        "we would say that both $\\mathcal{A}$ and $\\mathcal{B}$ occurred.\n",
        "On the other hand, if $z = 3$,\n",
        "then $\\mathcal{A}$ did not occur\n",
        "but $\\mathcal{B}$ did.\n",
        "\n",
        "\n",
        "A *probability* function maps events\n",
        "onto real values ${P: \\mathcal{A} \\subseteq \\mathcal{S} \\rightarrow [0,1]}$.\n",
        "The probability, denoted $P(\\mathcal{A})$, of an event $\\mathcal{A}$\n",
        "in the given sample space $\\mathcal{S}$,\n",
        "has the following properties:\n",
        "\n",
        "* The probability of any event $\\mathcal{A}$ is a nonnegative real number, i.e., $P(\\mathcal{A}) \\geq 0$;\n",
        "* The probability of the entire sample space is $1$, i.e., $P(\\mathcal{S}) = 1$;\n",
        "* For any countable sequence of events $\\mathcal{A}_1, \\mathcal{A}_2, \\ldots$ that are *mutually exclusive* (i.e., $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., $P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$.\n",
        "\n",
        "These axioms of probability theory,\n",
        "proposed by :citet:`Kolmogorov.1933`,\n",
        "can be applied to rapidly derive a number of important consequences.\n",
        "For instance, it follows immediately\n",
        "that the probability of any event $\\mathcal{A}$\n",
        "*or* its complement $\\mathcal{A}'$ occurring is 1\n",
        "(because $\\mathcal{A} \\cup \\mathcal{A}' = \\mathcal{S}$).\n",
        "We can also prove that $P(\\emptyset) = 0$\n",
        "because $1 = P(\\mathcal{S} \\cup \\mathcal{S}') = P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset) = 1 + P(\\emptyset)$.\n",
        "Consequently, the probability of any event $\\mathcal{A}$\n",
        "*and* its complement $\\mathcal{A}'$ occurring simultaneously\n",
        "is $P(\\mathcal{A} \\cap \\mathcal{A}') = 0$.\n",
        "Informally, this tells us that impossible events\n",
        "have zero probability of occurring.\n",
        "\n",
        "\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "When we spoke about events like the roll of a die\n",
        "coming up odds or the first coin toss coming up heads,\n",
        "we were invoking the idea of a *random variable*.\n",
        "Formally, random variables are mappings\n",
        "from an underlying sample space\n",
        "to a set of (possibly many) values.\n",
        "You might wonder how a random variable\n",
        "is different from the sample space,\n",
        "since both are collections of outcomes.\n",
        "Importantly, random variables can be much coarser\n",
        "than the raw sample space.\n",
        "We can define a binary random variable like \"greater than 0.5\"\n",
        "even when the underlying sample space is infinite,\n",
        "e.g., points on the line segment between $0$ and $1$.\n",
        "Additionally, multiple random variables\n",
        "can share the same underlying sample space.\n",
        "For example \"whether my home alarm goes off\"\n",
        "and \"whether my house was burgled\"\n",
        "are both binary random variables\n",
        "that share an underlying sample space.\n",
        "Consequently, knowing the value taken by one random variable\n",
        "can tell us something about the likely value of another random variable.\n",
        "Knowing that the alarm went off,\n",
        "we might suspect that the house was likely burgled.\n",
        "\n",
        "\n",
        "Every value taken by a random variable corresponds\n",
        "to a subset of the underlying sample space.\n",
        "Thus the occurrence where the random variable $X$\n",
        "takes value $v$, denoted by $X=v$, is an *event*\n",
        "and $P(X=v)$ denotes its probability.\n",
        "Sometimes this notation can get clunky,\n",
        "and we can abuse notation when the context is clear.\n",
        "For example, we might use $P(X)$ to refer broadly\n",
        "to the *distribution* of $X$, i.e.,\n",
        "the function that tells us the probability\n",
        "that $X$ takes any given value.\n",
        "Other times we write expressions\n",
        "like $P(X,Y) = P(X) P(Y)$,\n",
        "as a shorthand to express a statement\n",
        "that is true for all of the values\n",
        "that the random variables $X$ and $Y$ can take, i.e.,\n",
        "for all $i,j$ it holds that $P(X=i \\textrm{ and } Y=j) = P(X=i)P(Y=j)$.\n",
        "Other times, we abuse notation by writing\n",
        "$P(v)$ when the random variable is clear from the context.\n",
        "Since an event in probability theory is a set of outcomes from the sample space,\n",
        "we can specify a range of values for a random variable to take.\n",
        "For example, $P(1 \\leq X \\leq 3)$ denotes the probability of the event $\\{1 \\leq X \\leq 3\\}$.\n",
        "\n",
        "\n",
        "Note that there is a subtle difference\n",
        "between *discrete* random variables,\n",
        "like flips of a coin or tosses of a die,\n",
        "and *continuous* ones,\n",
        "like the weight and the height of a person\n",
        "sampled at random from the population.\n",
        "In this case we seldom really care about\n",
        "someone's exact height.\n",
        "Moreover, if we took precise enough measurements,\n",
        "we would find that no two people on the planet\n",
        "have the exact same height.\n",
        "In fact, with fine enough measurements,\n",
        "you would never have the same height\n",
        "when you wake up and when you go to sleep.\n",
        "There is little point in asking about\n",
        "the exact probability that someone\n",
        "is 1.801392782910287192 meters tall.\n",
        "Instead, we typically care more about being able to say\n",
        "whether someone's height falls into a given interval,\n",
        "say between 1.79 and 1.81 meters.\n",
        "In these cases we work with probability *densities*.\n",
        "The height of exactly 1.80 meters\n",
        "has no probability, but nonzero density.\n",
        "To work out the probability assigned to an interval,\n",
        "we must take an *integral* of the density\n",
        "over that interval.\n",
        "\n",
        "## Multiple Random Variables\n",
        "\n",
        "You might have noticed that we could not even\n",
        "make it through the previous section without\n",
        "making statements involving interactions\n",
        "among multiple random variables\n",
        "(recall $P(X,Y) = P(X) P(Y)$).\n",
        "Most of machine learning\n",
        "is concerned with such relationships.\n",
        "Here, the sample space would be\n",
        "the population of interest,\n",
        "say customers who transact with a business,\n",
        "photographs on the Internet,\n",
        "or proteins known to biologists.\n",
        "Each random variable would represent\n",
        "the (unknown) value of a different attribute.\n",
        "Whenever we sample an individual from the population,\n",
        "we observe a realization of each of the random variables.\n",
        "Because the values taken by random variables\n",
        "correspond to subsets of the sample space\n",
        "that could be overlapping, partially overlapping,\n",
        "or entirely disjoint,\n",
        "knowing the value taken by one random variable\n",
        "can cause us to update our beliefs\n",
        "about which values of another random variable are likely.\n",
        "If a patient walks into a hospital\n",
        "and we observe that they\n",
        "are having trouble breathing\n",
        "and have lost their sense of smell,\n",
        "then we believe that they are more likely\n",
        "to have COVID-19 than we might\n",
        "if they had no trouble breathing\n",
        "and a perfectly ordinary sense of smell.\n",
        "\n",
        "\n",
        "When working with multiple random variables,\n",
        "we can construct events corresponding\n",
        "to every combination of values\n",
        "that the variables can jointly take.\n",
        "The probability function that assigns\n",
        "probabilities to each of these combinations\n",
        "(e.g. $A=a$ and $B=b$)\n",
        "is called the *joint probability* function\n",
        "and simply returns the probability assigned\n",
        "to the intersection of the corresponding subsets\n",
        "of the sample space.\n",
        "The *joint probability* assigned to the event\n",
        "where random variables $A$ and $B$\n",
        "take values $a$ and $b$, respectively,\n",
        "is denoted $P(A = a, B = b)$,\n",
        "where the comma indicates \"and\".\n",
        "Note that for any values $a$ and $b$,\n",
        "it follows that\n",
        "\n",
        "$$P(A=a, B=b) \\leq P(A=a) \\textrm{ and } P(A=a, B=b) \\leq P(B = b),$$\n",
        "\n",
        "since for $A=a$ and $B=b$ to happen,\n",
        "$A=a$ has to happen *and* $B=b$ also has to happen.\n",
        "Interestingly, the joint probability\n",
        "tells us all that we can know about these\n",
        "random variables in a probabilistic sense,\n",
        "and can be used to derive many other\n",
        "useful quantities, including recovering the\n",
        "individual distributions $P(A)$ and $P(B)$.\n",
        "To recover $P(A=a)$ we simply sum up\n",
        "$P(A=a, B=v)$ over all values $v$\n",
        "that the random variable $B$ can take:\n",
        "$P(A=a) = \\sum_v P(A=a, B=v)$.\n",
        "\n",
        "\n",
        "The ratio $\\frac{P(A=a, B=b)}{P(A=a)} \\leq 1$\n",
        "turns out to be extremely important.\n",
        "It is called the *conditional probability*,\n",
        "and is denoted via the \"$\\mid$\" symbol:\n",
        "\n",
        "$$P(B=b \\mid A=a) = P(A=a,B=b)/P(A=a).$$\n",
        "\n",
        "It tells us the new probability\n",
        "associated with the event $B=b$,\n",
        "once we condition on the fact $A=a$ took place.\n",
        "We can think of this conditional probability\n",
        "as restricting attention only to the subset\n",
        "of the sample space associated with $A=a$\n",
        "and then renormalizing so that\n",
        "all probabilities sum to 1.\n",
        "Conditional probabilities\n",
        "are in fact just ordinary probabilities\n",
        "and thus respect all of the axioms,\n",
        "as long as we condition all terms\n",
        "on the same event and thus\n",
        "restrict attention to the same sample space.\n",
        "For instance, for disjoint events\n",
        "$\\mathcal{B}$ and $\\mathcal{B}'$, we have that\n",
        "$P(\\mathcal{B} \\cup \\mathcal{B}' \\mid A = a) = P(\\mathcal{B} \\mid A = a) + P(\\mathcal{B}' \\mid A = a)$.\n",
        "\n",
        "\n",
        "Using the definition of conditional probabilities,\n",
        "we can derive the famous result called *Bayes' theorem*.\n",
        "By construction, we have that $P(A, B) = P(B\\mid A) P(A)$\n",
        "and $P(A, B) = P(A\\mid B) P(B)$.\n",
        "Combining both equations yields\n",
        "$P(B\\mid A) P(A) = P(A\\mid B) P(B)$ and hence\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}.$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This simple equation has profound implications because\n",
        "it allows us to reverse the order of conditioning.\n",
        "If we know how to estimate $P(B\\mid A)$, $P(A)$, and $P(B)$,\n",
        "then we can estimate $P(A\\mid B)$.\n",
        "We often find it easier to estimate one term directly\n",
        "but not the other and Bayes' theorem can come to the rescue here.\n",
        "For instance, if we know the prevalence of symptoms for a given disease,\n",
        "and the overall prevalences of the disease and symptoms, respectively,\n",
        "we can determine how likely someone is\n",
        "to have the disease based on their symptoms.\n",
        "In some cases we might not have direct access to $P(B)$,\n",
        "such as the prevalence of symptoms.\n",
        "In this case a simplified version of Bayes' theorem comes in handy:\n",
        "\n",
        "$$P(A \\mid B) \\propto P(B \\mid A) P(A).$$\n",
        "\n",
        "Since we know that $P(A \\mid B)$ must be normalized to $1$, i.e., $\\sum_a P(A=a \\mid B) = 1$,\n",
        "we can use it to compute\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_a P(B \\mid A=a) P(A = a)}.$$\n",
        "\n",
        "In Bayesian statistics, we think of an observer\n",
        "as possessing some (subjective) prior beliefs\n",
        "about the plausibility of the available hypotheses\n",
        "encoded in the *prior* $P(H)$,\n",
        "and a *likelihood function* that says how likely\n",
        "one is to observe any value of the collected evidence\n",
        "for each of the hypotheses in the class $P(E \\mid H)$.\n",
        "Bayes' theorem is then interpreted as telling us\n",
        "how to update the initial *prior* $P(H)$\n",
        "in light of the available evidence $E$\n",
        "to produce *posterior* beliefs\n",
        "$P(H \\mid E) = \\frac{P(E \\mid H) P(H)}{P(E)}$.\n",
        "Informally, this can be stated as\n",
        "\"posterior equals prior times likelihood, divided by the evidence\".\n",
        "Now, because the evidence $P(E)$ is the same for all hypotheses,\n",
        "we can get away with simply normalizing over the hypotheses.\n",
        "\n",
        "Note that $\\sum_a P(A=a \\mid B) = 1$ also allows us to *marginalize* over random variables. That is, we can drop variables from a joint distribution such as $P(A, B)$. After all, we have that\n",
        "\n",
        "$$\\sum_a P(B \\mid A=a) P(A=a) = \\sum_a P(B, A=a) = P(B).$$\n",
        "\n",
        "Independence is another fundamentally important concept\n",
        "that forms the backbone of\n",
        "many important ideas in statistics.\n",
        "In short, two variables are *independent*\n",
        "if conditioning on the value of $A$ does not\n",
        "cause any change to the probability distribution\n",
        "associated with $B$ and vice versa.\n",
        "More formally, independence, denoted $A \\perp B$,\n",
        "requires that $P(A \\mid B) = P(A)$ and, consequently,\n",
        "that $P(A,B) = P(A \\mid B) P(B) = P(A) P(B)$.\n",
        "Independence is often an appropriate assumption.\n",
        "For example, if the random variable $A$\n",
        "represents the outcome from tossing one fair coin\n",
        "and the random variable $B$\n",
        "represents the outcome from tossing another,\n",
        "then knowing whether $A$ came up heads\n",
        "should not influence the probability\n",
        "of $B$ coming up heads.\n",
        "\n",
        "\n",
        "Independence is especially useful when it holds among the successive\n",
        "draws of our data from some underlying distribution\n",
        "(allowing us to make strong statistical conclusions)\n",
        "or when it holds among various variables in our data,\n",
        "allowing us to work with simpler models\n",
        "that encode this independence structure.\n",
        "On the other hand, estimating the dependencies\n",
        "among random variables is often the very aim of learning.\n",
        "We care to estimate the probability of disease given symptoms\n",
        "specifically because we believe\n",
        "that diseases and symptoms are *not* independent.\n",
        "\n",
        "\n",
        "Note that because conditional probabilities are proper probabilities,\n",
        "the concepts of independence and dependence also apply to them.\n",
        "Two random variables $A$ and $B$ are *conditionally independent*\n",
        "given a third variable $C$ if and only if $P(A, B \\mid C) = P(A \\mid C)P(B \\mid C)$.\n",
        "Interestingly, two variables can be independent in general\n",
        "but become dependent when conditioning on a third.\n",
        "This often occurs when the two random variables $A$ and $B$\n",
        "correspond to causes of some third variable $C$.\n",
        "For example, broken bones and lung cancer might be independent\n",
        "in the general population but if we condition on being in the hospital\n",
        "then we might find that broken bones are negatively correlated with lung cancer.\n",
        "That is because the broken bone *explains away* why some person is in the hospital\n",
        "and thus lowers the probability that they are hospitalized because of having lung cancer.\n",
        "\n",
        "\n",
        "And conversely, two dependent random variables\n",
        "can become independent upon conditioning on a third.\n",
        "This often happens when two otherwise unrelated events\n",
        "have a common cause.\n",
        "Shoe size and reading level are highly correlated\n",
        "among elementary school students,\n",
        "but this correlation disappears if we condition on age.\n",
        "\n",
        "\n",
        "\n",
        "## An Example\n",
        ":label:`subsec_probability_hiv_app`\n",
        "\n",
        "Let's put our skills to the test.\n",
        "Assume that a doctor administers an HIV test to a patient.\n",
        "This test is fairly accurate and fails only with 1% probability\n",
        "if the patient is healthy but reported as diseased,\n",
        "i.e., healthy patients test positive in 1% of cases.\n",
        "Moreover, it never fails to detect HIV if the patient actually has it.\n",
        "We use $D_1 \\in \\{0, 1\\}$ to indicate the diagnosis\n",
        "($0$ if negative and $1$ if positive)\n",
        "and $H \\in \\{0, 1\\}$ to denote the HIV status.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_1 = 1 \\mid H)$        |     1 |  0.01 |\n",
        "| $P(D_1 = 0 \\mid H)$        |     0 |  0.99 |\n",
        "\n",
        "Note that the column sums are all 1 (but the row sums do not),\n",
        "since they are conditional probabilities.\n",
        "Let's compute the probability of the patient having HIV\n",
        "if the test comes back positive, i.e., $P(H = 1 \\mid D_1 = 1)$.\n",
        "Intuitively this is going to depend on how common the disease is,\n",
        "since it affects the number of false alarms.\n",
        "Assume that the population is fairly free of the disease, e.g., $P(H=1) = 0.0015$.\n",
        "To apply Bayes' theorem, we need to apply marginalization\n",
        "to determine\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1)\n",
        "=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\\\\n",
        "=& P(D_1=1 \\mid H=0) P(H=0) + P(D_1=1 \\mid H=1) P(H=1) \\\\\n",
        "=& 0.011485.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This leads us to\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1=1 \\mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$\n",
        "\n",
        "In other words, there is only a 13.06% chance\n",
        "that the patient actually has HIV,\n",
        "despite the test being pretty accurate.\n",
        "As we can see, probability can be counterintuitive.\n",
        "What should a patient do upon receiving such terrifying news?\n",
        "Likely, the patient would ask the physician\n",
        "to administer another test to get clarity.\n",
        "The second test has different characteristics\n",
        "and it is not as good as the first one.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_2 = 1 \\mid H)$          |  0.98 |  0.03 |\n",
        "| $P(D_2 = 0 \\mid H)$          |  0.02 |  0.97 |\n",
        "\n",
        "Unfortunately, the second test comes back positive, too.\n",
        "Let's calculate the requisite probabilities to invoke Bayes' theorem\n",
        "by assuming conditional independence:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 0)\n",
        "& = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)\n",
        "=& 0.0003, \\\\\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 1)\n",
        "& = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)\n",
        "=& 0.98.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we can apply marginalization to obtain the probability\n",
        "that both tests come back positive:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "&P(D_1 = 1, D_2 = 1)\\\\\n",
        "&= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\\\\n",
        "&= P(D_1 = 1, D_2 = 1 \\mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \\mid H = 1)P(H=1)\\\\\n",
        "&= 0.00176955.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Finally, the probability of the patient having HIV given that both tests are positive is\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1, D_2 = 1)\n",
        "= \\frac{P(D_1 = 1, D_2 = 1 \\mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}\n",
        "= 0.8307.$$\n",
        "\n",
        "That is, the second test allowed us to gain much higher confidence that not all is well.\n",
        "Despite the second test being considerably less accurate than the first one,\n",
        "it still significantly improved our estimate.\n",
        "The assumption of both tests being conditionally independent of each other\n",
        "was crucial for our ability to generate a more accurate estimate.\n",
        "Take the extreme case where we run the same test twice.\n",
        "In this situation we would expect the same outcome both times,\n",
        "hence no additional insight is gained from running the same test again.\n",
        "The astute reader might have noticed that the diagnosis behaved\n",
        "like a classifier hiding in plain sight\n",
        "where our ability to decide whether a patient is healthy\n",
        "increases as we obtain more features (test outcomes).\n",
        "\n",
        "\n",
        "## Expectations\n",
        "\n",
        "Often, making decisions requires not just looking\n",
        "at the probabilities assigned to individual events\n",
        "but composing them together into useful aggregates\n",
        "that can provide us with guidance.\n",
        "For example, when random variables take continuous scalar values,\n",
        "we often care about knowing what value to expect *on average*.\n",
        "This quantity is formally called an *expectation*.\n",
        "If we are making investments,\n",
        "the first quantity of interest\n",
        "might be the return we can expect,\n",
        "averaging over all the possible outcomes\n",
        "(and weighting by the appropriate probabilities).\n",
        "For instance, say that with 50% probability,\n",
        "an investment might fail altogether,\n",
        "with 40% probability it might provide a 2$\\times$ return,\n",
        "and with 10% probability it might provide a 10$\\times$ return 10$\\times$.\n",
        "To calculate the expected return,\n",
        "we sum over all returns, multiplying each\n",
        "by the probability that they will occur.\n",
        "This yields the expectation\n",
        "$0.5 \\cdot 0 + 0.4 \\cdot 2 + 0.1 \\cdot 10 = 1.8$.\n",
        "Hence the expected return is 1.8$\\times$.\n",
        "\n",
        "\n",
        "In general, the *expectation* (or average)\n",
        "of the random variable $X$ is defined as\n",
        "\n",
        "$$E[X] = E_{x \\sim P}[x] = \\sum_{x} x P(X = x).$$\n",
        "\n",
        "Likewise, for densities we obtain $E[X] = \\int x \\;dp(x)$.\n",
        "Sometimes we are interested in the expected value\n",
        "of some function of $x$.\n",
        "We can calculate these expectations as\n",
        "\n",
        "$$E_{x \\sim P}[f(x)] = \\sum_x f(x) P(x) \\textrm{ and } E_{x \\sim P}[f(x)] = \\int f(x) p(x) \\;dx$$\n",
        "\n",
        "for discrete probabilities and densities, respectively.\n",
        "Returning to the investment example from above,\n",
        "$f$ might be the *utility* (happiness)\n",
        "associated with the return.\n",
        "Behavior economists have long noted\n",
        "that people associate greater disutility\n",
        "with losing money than the utility gained\n",
        "from earning one dollar relative to their baseline.\n",
        "Moreover, the value of money tends to be sub-linear.\n",
        "Possessing 100k dollars versus zero dollars\n",
        "can make the difference between paying the rent,\n",
        "eating well, and enjoying quality healthcare\n",
        "versus suffering through homelessness.\n",
        "On the other hand, the gains due to possessing\n",
        "200k versus 100k are less dramatic.\n",
        "Reasoning like this motivates the cliché\n",
        "that \"the utility of money is logarithmic\".\n",
        "\n",
        "\n",
        "If  the utility associated with a total loss were $-1$,\n",
        "and the utilities associated with returns of $1$, $2$, and $10$\n",
        "were $1$, $2$ and $4$, respectively,\n",
        "then the expected happiness of investing\n",
        "would be $0.5 \\cdot (-1) + 0.4 \\cdot 2 + 0.1 \\cdot 4 = 0.7$\n",
        "(an expected loss of utility of 30%).\n",
        "If indeed this were your utility function,\n",
        "you might be best off keeping the money in the bank.\n",
        "\n",
        "For financial decisions,\n",
        "we might also want to measure\n",
        "how *risky* an investment is.\n",
        "Here, we care not just about the expected value\n",
        "but how much the actual values tend to *vary*\n",
        "relative to this value.\n",
        "Note that we cannot just take\n",
        "the expectation of the difference\n",
        "between the actual and expected values.\n",
        "This is because the expectation of a difference\n",
        "is the difference of the expectations,\n",
        "i.e., $E[X - E[X]] = E[X] - E[E[X]] = 0$.\n",
        "However, we can look at the expectation\n",
        "of any non-negative function of this difference.\n",
        "The *variance* of a random variable is calculated by looking\n",
        "at the expected value of the *squared* differences:\n",
        "\n",
        "$$\\textrm{Var}[X] = E\\left[(X - E[X])^2\\right] = E[X^2] - E[X]^2.$$\n",
        "\n",
        "Here the equality follows by expanding\n",
        "$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$\n",
        "and taking expectations for each term.\n",
        "The square root of the variance is another\n",
        "useful quantity called the *standard deviation*.\n",
        "While this and the variance\n",
        "convey the same information (either can be calculated from the other),\n",
        "the standard deviation has the nice property\n",
        "that it is expressed in the same units\n",
        "as the original quantity represented\n",
        "by the random variable.\n",
        "\n",
        "Lastly, the variance of a function\n",
        "of a random variable\n",
        "is defined analogously as\n",
        "\n",
        "$$\\textrm{Var}_{x \\sim P}[f(x)] = E_{x \\sim P}[f^2(x)] - E_{x \\sim P}[f(x)]^2.$$\n",
        "\n",
        "Returning to our investment example,\n",
        "we can now compute the variance of the investment.\n",
        "It is given by $0.5 \\cdot 0 + 0.4 \\cdot 2^2 + 0.1 \\cdot 10^2 - 1.8^2 = 8.36$.\n",
        "For all intents and purposes this is a risky investment.\n",
        "Note that by mathematical convention mean and variance\n",
        "are often referenced as $\\mu$ and $\\sigma^2$.\n",
        "This is particularly the case whenever we use it\n",
        "to parametrize a Gaussian distribution.\n",
        "\n",
        "In the same way as we introduced expectations\n",
        "and variance for *scalar* random variables,\n",
        "we can do so for vector-valued ones.\n",
        "Expectations are easy, since we can apply them elementwise.\n",
        "For instance, $\\boldsymbol{\\mu} \\stackrel{\\textrm{def}}{=} E_{\\mathbf{x} \\sim P}[\\mathbf{x}]$\n",
        "has coordinates $\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$.\n",
        "*Covariances* are more complicated.\n",
        "We define them by taking expectations of the *outer product*\n",
        "of the difference between random variables and their mean:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} \\stackrel{\\textrm{def}}{=} \\textrm{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right].$$\n",
        "\n",
        "This matrix $\\boldsymbol{\\Sigma}$ is referred to as the covariance matrix.\n",
        "An easy way to see its effect is to consider some vector $\\mathbf{v}$\n",
        "of the same size as $\\mathbf{x}$.\n",
        "It follows that\n",
        "\n",
        "$$\\mathbf{v}^\\top \\boldsymbol{\\Sigma} \\mathbf{v} = E_{\\mathbf{x} \\sim P}\\left[\\mathbf{v}^\\top(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{v}\\right] = \\textrm{Var}_{x \\sim P}[\\mathbf{v}^\\top \\mathbf{x}].$$\n",
        "\n",
        "As such, $\\boldsymbol{\\Sigma}$ allows us to compute the variance\n",
        "for any linear function of $\\mathbf{x}$\n",
        "by a simple matrix multiplication.\n",
        "The off-diagonal elements tell us how correlated the coordinates are:\n",
        "a value of 0 means no correlation,\n",
        "where a larger positive value\n",
        "means that they are more strongly correlated.\n",
        "\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "In machine learning, there are many things to be uncertain about!\n",
        "We can be uncertain about the value of a label given an input.\n",
        "We can be uncertain about the estimated value of a parameter.\n",
        "We can even be uncertain about whether data arriving at deployment\n",
        "is even from the same distribution as the training data.\n",
        "\n",
        "By *aleatoric uncertainty*, we mean uncertainty\n",
        "that is intrinsic to the problem,\n",
        "and due to genuine randomness\n",
        "unaccounted for by the observed variables.\n",
        "By *epistemic uncertainty*, we mean uncertainty\n",
        "over a model's parameters, the sort of uncertainty\n",
        "that we can hope to reduce by collecting more data.\n",
        "We might have epistemic uncertainty\n",
        "concerning the probability\n",
        "that a coin turns up heads,\n",
        "but even once we know this probability,\n",
        "we are left with aleatoric uncertainty\n",
        "about the outcome of any future toss.\n",
        "No matter how long we watch someone tossing a fair coin,\n",
        "we will never be more or less than 50% certain\n",
        "that the next toss will come up heads.\n",
        "These terms come from mechanical modeling,\n",
        "(see e.g., :citet:`Der-Kiureghian.Ditlevsen.2009` for a review on this aspect of [uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)).\n",
        "It is worth noting, however, that these terms constitute a slight abuse of language.\n",
        "The term *epistemic* refers to anything concerning *knowledge*\n",
        "and thus, in the philosophical sense, all uncertainty is epistemic.\n",
        "\n",
        "\n",
        "We saw that sampling data from some unknown probability distribution\n",
        "can provide us with information that can be used to estimate\n",
        "the parameters of the data generating distribution.\n",
        "That said, the rate at which this is possible can be quite slow.\n",
        "In our coin tossing example (and many others)\n",
        "we can do no better than to design estimators\n",
        "that converge at a rate of $1/\\sqrt{n}$,\n",
        "where $n$ is the sample size (e.g., the number of tosses).\n",
        "This means that by going from 10 to 1000 observations (usually a very achievable task)\n",
        "we see a tenfold reduction of uncertainty,\n",
        "whereas the next 1000 observations help comparatively little,\n",
        "offering only a 1.41 times reduction.\n",
        "This is a persistent feature of machine learning:\n",
        "while there are often easy gains, it takes a very large amount of data,\n",
        "and often with it an enormous amount of computation, to make further gains.\n",
        "For an empirical review of this fact for large scale language models see :citet:`Revels.Lubin.Papamarkou.2016`.\n",
        "\n",
        "We also sharpened our language and tools for statistical modeling.\n",
        "In the process of that we learned about conditional probabilities\n",
        "and about one of the most important equations in statistics---Bayes' theorem.\n",
        "It is an effective tool for decoupling information conveyed by data\n",
        "through a likelihood term $P(B \\mid A)$ that addresses\n",
        "how well observations $B$ match a choice of parameters $A$,\n",
        "and a prior probability $P(A)$ which governs how plausible\n",
        "a particular choice of $A$ was in the first place.\n",
        "In particular, we saw how this rule can be applied\n",
        "to assign probabilities to diagnoses,\n",
        "based on the efficacy of the test *and*\n",
        "the prevalence of the disease itself (i.e., our prior).\n",
        "\n",
        "Lastly, we introduced a first set of nontrivial questions\n",
        "about the effect of a specific probability distribution,\n",
        "namely expectations and variances.\n",
        "While there are many more than just linear and quadratic\n",
        "expectations for a probability distribution,\n",
        "these two already provide a good deal of knowledge\n",
        "about the possible behavior of the distribution.\n",
        "For instance, [Chebyshev's inequality](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality)\n",
        "states that $P(|X - \\mu| \\geq k \\sigma) \\leq 1/k^2$,\n",
        "where $\\mu$ is the expectation, $\\sigma^2$ is the variance of the distribution,\n",
        "and $k > 1$ is a confidence parameter of our choosing.\n",
        "It tells us that draws from a distribution lie\n",
        "with at least 50% probability\n",
        "within a $[-\\sqrt{2} \\sigma, \\sqrt{2} \\sigma]$\n",
        "interval centered on the expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Give an example where observing more data can reduce the amount of uncertainty about the outcome to an arbitrarily low level.\n",
        "1. Give an example where observing more data will only reduce the amount of uncertainty up to a point and then no further. Explain why this is the case and where you expect this point to occur.\n",
        "1. We empirically demonstrated convergence to the mean for the toss of a coin. Calculate the variance of the estimate of the probability that we see a head after drawing $n$ samples.\n",
        "    1. How does the variance scale with the number of observations?\n",
        "    1. Use Chebyshev's inequality to bound the deviation from the expectation.\n",
        "    1. How does it relate to the central limit theorem?\n",
        "1. Assume that we draw $m$ samples $x_i$ from a probability distribution with zero mean and unit variance. Compute the averages $z_m \\stackrel{\\textrm{def}}{=} m^{-1} \\sum_{i=1}^m x_i$. Can we apply Chebyshev's inequality for every $z_m$ independently? Why not?\n",
        "1. Given two events with probability $P(\\mathcal{A})$ and $P(\\mathcal{B})$, compute upper and lower bounds on $P(\\mathcal{A} \\cup \\mathcal{B})$ and $P(\\mathcal{A} \\cap \\mathcal{B})$. Hint: graph the situation using a [Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram).\n",
        "1. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? Hint: this is a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "1. In :numref:`subsec_probability_hiv_app`, assume that the outcomes of the two tests are not independent. In particular assume that either test on its own has a false positive rate of 10% and a false negative rate of 1%. That is, assume that $P(D =1 \\mid H=0) = 0.1$ and that $P(D = 0 \\mid H=1) = 0.01$. Moreover, assume that for $H = 1$ (infected) the test outcomes are conditionally independent, i.e., that $P(D_1, D_2 \\mid H=1) = P(D_1 \\mid H=1) P(D_2 \\mid H=1)$ but that for healthy patients the outcomes are coupled via $P(D_1 = D_2 = 1 \\mid H=0) = 0.02$.\n",
        "    1. Work out the joint probability table for $D_1$ and $D_2$, given $H=0$ based on the information you have so far.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after one test returns positive. You can assume the same baseline probability $P(H=1) = 0.0015$ as before.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after both tests return positive.\n",
        "1. Assume that you are an asset manager for an investment bank and you have a choice of stocks $s_i$ to invest in. Your portfolio needs to add up to $1$ with weights $\\alpha_i$ for each stock. The stocks have an average return $\\boldsymbol{\\mu} = E_{\\mathbf{s} \\sim P}[\\mathbf{s}]$ and covariance $\\boldsymbol{\\Sigma} = \\textrm{Cov}_{\\mathbf{s} \\sim P}[\\mathbf{s}]$.\n",
        "    1. Compute the expected return for a given portfolio $\\boldsymbol{\\alpha}$.\n",
        "    1. If you wanted to maximize the return of the portfolio, how should you choose your investment?\n",
        "    1. Compute the *variance* of the portfolio.\n",
        "    1. Formulate an optimization problem of maximizing the return while keeping the variance constrained to an upper bound. This is the Nobel-Prize winning [Markovitz portfolio](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`. To solve it you will need a quadratic programming solver, something way beyond the scope of this book.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126c2b93",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "126c2b93"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/37)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}